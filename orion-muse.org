#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:{} arch:headline
#+OPTIONS: author:t c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+OPTIONS: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t
#+OPTIONS: tags:t tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+TITLE: orion-muse
#+AUTHOR: William Henney
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+TODO: TODO NEXT STARTED | DONE CANCELED
* Short term goals
:PROPERTIES:
:ID:       706697F5-E600-4446-A4A4-C467A96CBD2C
:END:
** [0/7] Before Skype meeting Nashville+2 
DEADLINE: <2015-11-04 Wed>
*** TODO Improve continuum subtraction in extracting lines
+ Some lines such as O II 4650 complex need more attention
+ Need more flexible sizing of line and continuum windows
*** TODO Do extinction correction for all lines
+ This means first settling on a reddening curve
+ Simplest approach is to use Hb/Ha and then apply Blagrave to everything
  + pyneb.extinction.red_corr.RedCorr(law='CCM89 Bal07') could help
  + I think they mean =Bla= instead of =Bal=
+ Of course, there are issues with that since E(Hb-Ha) plus R_V=5 reddening law seems to underpredict the extinction, at least in the dark bay
*** NEXT Deal with sky subtraction
+ Plot weak line brightness against similar ionization strong line brightness
+ Look for an obvious floor to the weak line brightness to give estimate of the sky brightness
+ Subtract from line maps before taking ratios
*** STARTED [/] Estimate noise in MUSE maps
+ [X] Use the error cube from the original FITS file
  + Need to do this on server (or maybe on hypatia)
  + [2015-10-29 Thu 11:28] I now have the cubes on hypatia (or on their way from nil)
  + I have put them in the =BigFiles/= folder, *which is excluded from Dropbox*
  + They are 6.8GB each = 47.6 GB all together
    + There is not enough disk space on my laptop for them
+ [ ]Make fuzzed versions of the line maps 
+ [ ]Propagate the variance through all the data reduction steps
+ Then we can fuzz the line maps by adding Gaussian noise.
  + Actually it would be best to fuzz the data cubes directly. And then to follow exactly the same steps with the fuzzed data. We can then calculate the pixel by pixel differences between T from fuzzed and original cubes. The dispersion in this is then our best estimate for the noise contribution to t-squared.
  + We can also then use this to generate maps with a guaranteed signal to noise by using multi scale binning. Important here in the case of ratios to use the same mask hierarchy for all lines that contribute to the final quantity.
*** TODO Look at noise behavior with binning for "constant" ratios
+ Such as 6363/6300, 6583/6548, 5007/4959, etc
*** TODO Write up the CEL-ORL T indicator stuff for O++
+ Even though this is not for the current paper, I don't want to forget about it and it would be good to get Manuel's input
*** TODO Write up Dust extinction complications stuff
+ Show all the different reddening indicators
  + Balmer decrement
  + Paschen decrements
  + Balmer-Paschen decrement
    + This is the longest wavelength range (if we used 4861 to 9229)
    + With 6563/9229 we have
      + 1.41 factor in ratio
      + 
  + [Ar III] and [O III] ratio
    + Small wavelength range, but high S/N and rock solid intrinsic ratio
    + [Ar III] 7751/7136 is 9% change in wavelength
      + 15% change in ratio between SW cloud and HH 202 region
    + [O III] 5007/4959 is a 1% change in wavelength
      + 1% change in ratio between SW cloud and HH 202 region
+ 
** Before Skype meeting Nashville+3
DEADLINE: <2015-11-10 Tue>

* Medium term goals
Holding area for tasks that will get moved to [[id:706697F5-E600-4446-A4A4-C467A96CBD2C][Short term goals]]
** Fit Gaussians to blended lines in MUSE data
** Write script to generate figures of MUSE maps
+ Use WCSAxes or APLpy?
** Write up WFC3 calibration material
+ This will be in an appendix
+ We already have the figures sorted
+ Copy material from the original draft of the paper
** Write about plane-of-sky t^2 theory
+ Suppression of fluctuations on scales smaller than LOS depth
* TODO Important things to follow up
** TODO [#A] Remove the sky components
This is very important for the weak lines
** [Fe III] 5270
+ This shows lots of wonderful structure in the jet source regions
  + HH529 and counterjet?
+ Also strong in NW extension of HH202
+ Shows jet that can be maybe linked with HH203/204
+ Our WFC3 469N filter shows a small field of this around Orion S
+ MUSE spectrum starts at 4595, so we should also have [Fe III] 4702, 4658, which are of similar brightness to 5270, plus a host of weaker ones - see the Manuel notes.
  + Yes, they are seen - 4658 is the best
** O I 5577
+ Dominated by sky
  + Need to subtract it in square sections
  + Calculate histogram of values for each tile, and take the histogram peak as the sky value
+ Has some interesting point sources - presumably proplyd disks, but also HH201
+ Also diffuse emission from Orion S and Bar
+ Ratio 5577/6300 should be T-sensitive
** [N I] 5199
+ Spatial distribution confirms fluorescent origin
+ Very bright in proplyds
+ But why is it absent in HH 203 and weak in 204 - also absent in 202
  + But strong in 201
** [Fe II] lines
+ These are varied
+ 5262 looks like fluorescence in PDR
+ 7453 looks like collisionally excited at IF
+ 8617 (strongest) looks intermediate between the two
** Si II lines
+ Extremely varied
+ Combination of recomb and fluorescence
+ Or perhaps fluorescence with different opacities
  + So some fluoresce in the ionized gas, and some in the neutral
+ There are linear features seen in 6371 and nowhere else

** O II complex at 4650
+ 4649 and 4651 are severely blended
  + Disentangling these is vital for getting an O II density diagnostic
+ We have to sum over a large area to get enough s/n to fit for all the O II components
+ We could maybe use the mean wavelength of the 4649+51 blend as a proxy for the 4649/51 ratio, but we would have to correct for the kinematics, using perhaps [O III] or, better yet, an unblended line of the same multiplet
  + But the only one is  4676 and that is too weak
  + We can't really use 4639+42 because that is blended with N II 4643 and N III 4641
** O I 8446 multiplet
+ This is way brighter than the bluer O I lines
+ Excellent for tracing kinematics of neutral gas
** [C I] 8727.13
+ This has a different morphology than anything else!
+ Redshifted filament pointing down SSW from Orion S
** [Cl IV] 8045.62
+ The highest ionization line
+ Traces very interior gas, and also ORL clump
** [Ar III] 7135.78
+ This is excellent for velocity mapping
+ The velocity resolution is better at longer wavelengths
+ You can see blue-shifted and red-shifted flows easily
** Paschen lines 
Doing the ratio with Ha would be good for reddening curve
*** Comparing Hb/Ha with Paschen/Balmer
:PROPERTIES:
:ID:       236AC762-7034-42E9-83BC-754A68346A23
:END:
The reddenings are very similar, except for two things:
1. Some very opaque filaments show up as reddening in 9229/6563, but minima in reddening in 4861/6563 (and high extinction in Ha-radio)
   - I'm thinking this could be due to blocking all the light behind in 6563 and 4861, so being dominated by the foreground extinction
   - Whereas not totally opaque at 9229 (but extinction curve is not /that/ steep, is it?)
2. Thin strip on neutral side of bar has increased Hb/Ha reddening but barely visible in 9229/6563 - and has /negative/ Ha-radio estinction in parts
   - This must be scattering!
   - Multiple scattering so that it is red rather than blue
   - No real H+ emission, so not see in radio, leading to negative Ha-radio extinction
** Ca II permitted lines in HST3 170-337
+ This is a proplyd with redshifted jet
+ It has components that look like they are blue wings of some Paschen lines
  + But they can't be because only some Pa lines have them
  + Instead they must be something else
  + 8495, 8538, 8658
  + Turns out that they are Ca II lines, and these are well-known in T Tauri stars
    + EW(Ca II) correlates with mass accretion rate
    + Moto'oka and Itoh (2015)
    + Looking at the full-res cube, this is restricted to the star - not extended
    + Also seen in many other young stars/proplyds
      + E.g., LV2, LV5, LL Ori and many more
+ Also red component to [S III] 9069
+ In blue end of spectrum He I lines at 4921 and 5016 show a red component
+ Also 5167, 5183, 5197, 5231 unidentified lines
  + plus other weaker ones
  + These may well be photospheric
+ Strong [N II] 5755 but it is not redshifted
+ C II (?) 5890 line shows up maybe
  + But wav doesn't quite match
  + Could be unidentified lines at 5887 and 5894
+ More lines at 6135, 6147, 6240, 6245 - very weak
+ More lines at 6430, 6453, 6514
** Weaker lines that might be interesting
+ Ne I 8892.22 - similar to O I
+ Ca I] 9052.16 but 9095.09 is missing so maybe something else
+ [O I] 5577.31 need to remove sky line but then there are some interesting little spots like HH 201
+ 5906 very weak line - I had classified it as Si I 5906.22, 5906.15, 5906.418, 5906.92 but this seems very unlikely since it is not seen in any of the low-ionization parts, only near the Trapezium, most strongly in the SW compact bar
** Using the absorption lines
+ The trouble here is that many of the best He II lines are bluer than the spectral range
+ He II 4686 works well
  + Deepest in th2A
  + One problem is that it is phase-dependent in th1C
+ He II 5411 has some potential, but is contaminated by [Fe III]
+ O II 4650 is seen in absorbtion right on th2A, but in the nebula it is swamped by the ORL emission lines
+ C IV 5801.35, 5811.97 are clearly seen in th1C spectrum and much weaker in th2A, absent in other trapezium stars
  + Unfortunately, they are very weak in the nebula
  + Requires integration over 15x15 arcsec box to have much s/n
+ N III 6633.9 is very interesting
  + Has absorption depth of 0.08 in Orion S region
  + But not seen in any OB stars 
  + Seen in th1E, which is G2V spectral type
    + (which Olivares et al 2013) say is not bound to Trapezium
    + And is also eclipsing binary (Morales-Calderón et al 2012)
    + But absorption depth there is only 0.05
  + Conclusion must be that we are seeing scattered light from an embedded yellow supergiant that is leaking out.
  + Some T Tauri stars show a Cr I line at 6630 but that has a very low EW ~0.01 A (Apenzeller et al 1986, Table III)
  + There are also lines around 6480 and 6490 in the nebular scattered light
    + Some stars show a strongish line around 6495

** DONE Looking at the strange broad NIR emission bump
CLOSED: [2015-08-13 Thu 11:15]
+ NO - This is just a second order Balmer line - see their paper!
+ Take the difference or ratio between 8570 A and 8552 A
+ Results are very disappointing
  + We see a vague form of the nebula in the ratio image
  + It looks similar to the continuum image, but not exactly the same
  + It doesn't look much like scattered continuum
  + And there is this instrumental tartan pattern superimposed on it
  + And it is also very noisy
  + Certainly not worth bothering with
  + Ratio image is even worse
#+BEGIN_SRC python :results output
  from astropy.io import fits
  import numpy as np

  cubehdu, = fits.open('muse-hr-data-wavsec6.fits')
  continuum = np.nanmean(cubehdu.data[441:446], axis=0)
  bump = np.nanmean(cubehdu.data[455:471], axis=0)
  fits.PrimaryHDU(header=cubehdu.header, data=bump-continuum).writeto('bump8600-diff.fits', clobber=True)
  fits.PrimaryHDU(header=cubehdu.header, data=bump/continuum).writeto('bump8600-ratio.fits', clobber=True)
#+END_SRC

#+RESULTS:

** Longer wavelength lines
| 7001.92 | O I      | 3 |                          |
| 7002.23 | O I      | 3 | blend                    |
| 7065.28 | He I     | 2 |                          |
| 7135.78 | [Ar III] | 1 | super strong             |
| 7155.14 | [Fe II]  | 4 |                          |
| 7231.34 | C II     | 3 |                          |
| 7236.42 | C II     | 3 |                          |
| 7254.15 | O I      | 3 | Also 7254.45, 7254.53    |
| 7281.35 | He I     | 3 |                          |
|  7290.3 | ?        | 4 | possibly [Fe II]         |
| 7318.39 | [O II]   | 1 | Also 7319.99             |
| 7329.66 | [O II]   | 1 | Also 7330.73             |
| 7377.83 | [Ni II]  | 4 |                          |
| 7411.61 | [Ni II]  | 5 |                          |
| 7442.30 | N I      | 5 |                          |
| 7452.54 | [Fe II]  | 4 |                          |
| 7468.31 | N I      | 4 |                          |
|---------+----------+---+--------------------------|
| 7751.10 | [Ar III] | 1 |                          |
| 7816.13 | He I     | 4 |                          |
| 7890.07 | Ca I]    | 4 |                          |
|    7900 | Sky      | 4 | Lots of sky lines        |
|    8000 | Sky      | 4 | in this spectral         |
| 8045.62 | [Cl IV]  | 4 | HIGH IONIZATION!         |
|    8100 | Sky      | 4 | range                    |
|---------+----------+---+--------------------------|
|    8189 | Fe I?    | 4 | ID uncertain             |
| 8200.36 | N I?     | 5 | very weak                |
| 8210.72 | N I      | 5 |                          |
| 8216.34 | N I      | 4 |                          |
| 8223.14 | N I      | 4 | Strongest component      |
|    8243 | ?        | 4 | O I? or Fe II?           |
|   8240+ | H I      | 4 | Lots of Paschen lines    |
| 8437.96 | H I      | 3 | Pa 18                    |
| 8446.36 | O I      | 2 | And 8444.25, 8444.76--   |
| 8467.25 | H I      | 2 | Pa 17                    |
| 8502.48 | H I      | 2 | Pa 16                    |
| 8545.38 | H I      | 2 | Pa 15                    |
| 8578.69 | [Cl II]  | 3 |                          |
| 8598.39 | H I      | 2 | Pa 14                    |
|    8600 | Bump?    | 4 | second order             |
| 8616.95 | [Fe II]  | 3 |                          |
| 8665.02 | H I      | 2 | Pa 13                    |
| 8680.28 | N I      | 4 | Strongest component      |
| 8683.40 | N I      | 4 |                          |
| 8686.15 | N I      | 4 |                          |
| 8703.25 | N I      | 4 |                          |
| 8711.70 | N I      | 4 |                          |
| 8718.83 | N I      | 5 | very weak                |
| 8727.13 | [C I]    | 4 | Different!               |
| 8733.43 | He I     | 5 | very weak                |
| 8750.47 | H I      | 2 |                          |
|---------+----------+---+--------------------------|
| 8862.79 | H I      | 2 |                          |
| 8892.22 | Ne I     | 4 |                          |
| 8996.99 | He I     | 5 |                          |
| 9014.91 | H I      | 2 | Pa 10                    |
|    9032 | ?        | 5 | low ionization shocks    |
| 9052.16 | Ca I]    | 5 |                          |
| 9068.90 | [S III]  | 1 |                          |
| 9095.09 | Ca I]    | 5 |                          |
| 9123.60 | [Cl II]  | 4 |                          |
| 9204.17 | O II?    | 5 | but looks low ionization |
| 9210.28 | He I     | 4 |                          |
| 9229.01 | H I      | 2 | Pa 9                     |
|    9267 | ??       | 5 | only in shock knots      |



* Extracting individual emission lines from MUSE cube

** Strong lines and others of primary interest
:PROPERTIES:
:TABLE_EXPORT_FILE: basic-line-list.tab
:TABLE_EXPORT_FORMAT: orgtbl-to-tsv
:END:
+ After editing, remember to export the table to file with =C-c t e=
#+name: basic-line-list
| Ion      |     wav0 | strength | blue cont | red cont | comment              |
|----------+----------+----------+-----------+----------+----------------------|
| O II     |  4650.00 |        4 |         1 |        0 | blend 4649.13,50.84  |
| [Fe III] |  4658.10 |        3 |         0 |        1 |                      |
| [Fe III] |  4701.62 |        4 |         1 |        1 |                      |
| H I      |  4861.32 |        1 |         1 |        1 |                      |
| [O III]  |  4958.91 |        1 |         1 |        1 |                      |
| [O III]  |  5006.84 |        1 |         1 |        1 |                      |
| He I     |  5015.68 |        3 |         0 |        1 |                      |
| Si II    |  5041.03 |        4 |         1 |        0 |                      |
| He I     |  5047.74 |        4 |         0 |        1 | No good cont!        |
| Si II    |  5055.98 |        4 |         0 |        1 |                      |
| [Ar III] |  5191.82 |        4 |         1 |        0 |                      |
| [N I]    |  5199.00 |        4 |         0 |        1 | Blend 5197.98,200.26 |
| [Fe II]  |  5261.61 |        4 |         1 |        0 |                      |
| [Fe III] |  5270.40 |        3 |         0 |        1 |                      |
| [Cl III] |  5517.71 |        3 |         1 |        1 |                      |
| [Cl III] |  5537.88 |        3 |         1 |        1 |                      |
| [O I]    |  5577.34 |        4 |         1 |        1 | Sky contamination    |
| [N II]   |  5755.08 |        4 |         1 |        1 |                      |
| He I     |  5875.62 |        1 |         1 |        1 |                      |
| C II     |  5889.78 |        4 |         1 |        1 | Na I sky blend       |
| N II     |  5931.78 |        4 |         1 |        1 |                      |
| N II     |  5941.65 |        4 |         1 |        1 |                      |
| N II     |  5952.39 |        4 |         1 |        0 |                      |
| Si II    |  5957.56 |        4 |         0 |        1 | Blend with O I?      |
| Si II    |  5978.93 |        4 |         1 |        1 |                      |
| O I      |  6046.23 |        4 |         1 |        1 |                      |
| [Fe II]  | 6133.433 |        4 |         1 |        1 | plus sky?            |
| [O I]    |  6300.30 |        3 |         1 |        1 |                      |
| [S III]  |  6312.06 |        3 |         1 |        1 |                      |
| Si II    |  6347.11 |        4 |         1 |        1 |                      |
| [O I]    |  6363.78 |        3 |         1 |        0 |                      |
| Si II    |  6371.36 |        4 |         0 |        1 |                      |
| [N II]   |  6548.05 |        2 |         1 |        1 |                      |
| H I      |  6562.79 |        1 |         1 |        1 |                      |
| C II     |  6578.05 |        5 |         1 |        0 |                      |
| [N II]   |  6583.45 |        2 |         1 |        1 |                      |
| He I     |  6678.15 |        2 |         1 |        1 |                      |
| [S II]   |  6716.44 |        3 |         1 |        1 |                      |
| [S II]   | 6730.816 |        3 |         1 |        1 |                      |
| O I      |  7001.92 |        3 |         1 |        1 |                      |
| He I     |  7065.28 |        2 |         1 |        1 |                      |
| [Ar III] |  7135.78 |        1 |         1 |        1 | super strong         |
| [O II]   |  7318.39 |        1 |         1 |        1 | Also 7319.99         |
| [O II]   |  7329.66 |        1 |         0 |        1 | Also 7330.73         |
| [Fe II]  |  7452.54 |        4 |         1 |        1 |                      |
| [Ar III] |  7751.10 |        1 |         1 |        1 |                      |
| [Cl IV]  |  8045.62 |        4 |         1 |        1 | HIGH IONIZATION!     |
| H I      |  8437.96 |        3 |         1 |        0 | Pa 18                |
| O I      |  8446.36 |        2 |         0 |        1 |                      |
| H I      |  8467.25 |        2 |         0 |        1 | Pa 17                |
| H I      |  8502.48 |        2 |         1 |        1 | Pa 16                |
| H I      |  8545.38 |        2 |         1 |        1 | Pa 15                |
| [Cl II]  |  8578.69 |        3 |         1 |        0 | Blend with 8582      |
| H I      |  8598.39 |        2 |         1 |        1 | Pa 14                |
| [Fe II]  |  8616.95 |        3 |         1 |        1 |                      |
| H I      |  8665.02 |        2 |         1 |        1 | Pa 13                |
| [C I]    |  8727.13 |        4 |         1 |        0 | Different!           |
| H I      |  8750.47 |        2 |         1 |        1 | Pa 12                |
| H I      |  8862.79 |        2 |         1 |        1 | Pa 11                |
| H I      |  9014.91 |        2 |         1 |        1 | Pa 10                |
| Ca I]    |  9052.16 |        5 |         1 |        0 |                      |
| [S III]  |  9068.90 |        1 |         1 |        1 |                      |
| Ca I]    |  9095.09 |        5 |         1 |        0 |                      |
| H I      |  9229.01 |        2 |         1 |        1 | Pa 9                 |

** Simple method with moments
+ This will work for any line that is sufficiently isolated

*** fuzz_utils.py: add Gaussian noise to data according to per pixel variance
+ This was remarkably easy - it turns out that the numpy random distributions take array arguments for the mean and std parameters
#+BEGIN_SRC python :tangle fuzz_utils.py
  import numpy as np

  def fuzz(data, variance, nfuzz=1):
      '''Return `nfuzz` fuzzed versions of `data` in which each pixel is
  replaced by a value taken from a Gaussian distribution with mean equal
  to `data` and sigma equal to sqrt of `variance` (which must have same
  shape as `data`).  Returns an array of shape `(nfuzz,) + shape(data)` in
  which each (hyper) plane is a distinct fuzzed version of the original

      '''
      newshape = (nfuzz,) + data.shape
      return np.random.normal(data, np.sqrt(variance), newshape)
    

#+END_SRC
*** Program to extract a single line extract-em-line.py
+ First go
  + Choose wavelength range around line
    + [ ]This should come from a velocity range really
  + Extract cube that is just the line
+ Revisited [2015-10-29 Thu]
  + We want to add "fuzzed" versions of the maps in which we add gaussian noise made from the variance
  + First we refactor the original extract-em-line.py so that it separates the finding of the wavelength window from the line extraction proper
  + This is because we don't want to fuzz the entire wavsec cube
  + The idea is that we will be able to re-use parts in the fuzz version


#+BEGIN_SRC python :tangle extract_utils.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.table import Table
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy import units as u
  from misc_utils import sanitize_string
  sys.path.append('/Users/will/Dropbox/OrionWest/')
  from helio_utils import waves2vels


  linetab = Table.read('basic-line-list.tab', format='ascii.tab')
  wavsectab = Table.read('wavsec-startwavs.tab', format='ascii.tab')

  def find_wavsec(wav):
      """Which wavsec chunk is this wavelength in"""
      return wavsectab['Section'][wav > wavsectab['CRVAL3']].max() 



#+END_SRC

#+BEGIN_SRC python :tangle extract-em-line.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.table import Table
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy import units as u
  from misc_utils import sanitize_string
  sys.path.append('/Users/will/Dropbox/OrionWest/')
  from helio_utils import waves2vels

  linetab = Table.read('basic-line-list.tab', format='ascii.tab')
  wavsectab = Table.read('wavsec-startwavs.tab', format='ascii.tab')

  def find_wavsec(wav):
      """Which wavsec chunk is this wavelength in"""
      return wavsectab['Section'][wav > wavsectab['CRVAL3']].max() 


  def save_linemap_files(wav, species, mapdir='LineMaps', usecont=[1, 1]):
      wavsec = find_wavsec(wav)
      wavsec_blue = find_wavsec(wav - 8.0)
      wavsec_red = find_wavsec(wav + 8.0)
      if (wavsec_blue != wavsec) or (wavsec_red != wavsec):
          print('Uh, oh - line straddles wavsecs', wavsec_blue, wavsec, wavsec_red)
          if 5000.0 < wav < 6000.0:
              print('But luckily we can use F547M window instead')
              fn = 'muse-hr-window-wfc3-f547m.fits'
          else:
              sys.exit('Unable to find a cube that contains wavelength range - sorry!')
      else:
          fn = 'muse-hr-data-wavsec{}.fits'.format(wavsec)
      hdulist = fits.open(fn)
      hdu = hdulist['DATA']
      w = WCS(hdu.header)
      helio_hdr = fits.open('muse-hr-window-wfc3-f656n.fits')[0].header
      maps, spec =  extract_line_maps(wav, hdu.data, w, helio_hdr, usecont)
      wavid = str(int(wav+0.5))
      # Save the maps to FITS file 
      for mapid, mapdata in maps.items():
          mhdu = fits.PrimaryHDU(header=w.celestial.to_header(), data=mapdata)
          mname = '{}/{}-{}-{}.fits'.format(mapdir, mapid, species, wavid)
          mhdu.writeto(mname, clobber=True)
      sname = '{}/spec1d-{}-{}.tab'.format(mapdir, species, wavid)
      # And save the spectrum to TSV file
      Table(spec).write(sname, format='ascii.tab')

  def extract_line_maps(wav, cube, wcube, helio_hdr,
                        usecont=[1, 1], dwav=4.0, dwavcont=8.0):
      """Extract line moments and continuum"""

      # outer range is wav +/- dwavcont
      wavs = (wav + dwavcont*np.array([-1, 1]))*u.Angstrom.to(u.m)
      _, _, (kout1, kout2) = wcube.all_world2pix([0, 0], [0, 0], wavs, 0)
      kout1, kout2 = int(kout1), int(kout2) + 2

      # inner range is wav +/- dwav
      wavs = (wav + dwav*np.array([-1, 1]))*u.Angstrom.to(u.m)
      _, _, (kin1, kin2) = wcube.all_world2pix([0, 0], [0, 0], wavs, 0)
      kin1, kin2 = int(kin1), int(kin2) + 2

      # find average continuum
      cont1 = np.nanmean(cube[kout1:kin1, :, :], axis=0)
      cont2 = np.nanmean(cube[kin2:kout2, :, :], axis=0)
      # Maybe don't use the continuum on one side (if contaminated)
      wt1, wt2 = usecont          
      avcont = (wt1*cont1 + wt2*cont2)/(wt1 + wt2)

      # Subtract to get pure line window
      linewin = cube[kin1:kin2, :, :] - avcont[None, :, :]
      # Now find moments
      nwin = kin2 - kin1
      _, _, winwavs = wcube.all_pix2world([0]*nwin, [0]*nwin, np.arange(kin1, kin2), 0)
      # Convert wavelengths to velocities
      winvels = waves2vels(winwavs*u.m.to(u.Angstrom), wav, helio_hdr, observatory='VLT4')
      mom0 = linewin.sum(axis=0)
      mom1 = np.sum(linewin*winvels[:, None, None], axis=0)
      vmean = mom1/mom0
      mom2 = np.sum(linewin*(winvels[:, None, None] - vmean)**2, axis=0)
      vsig = np.sqrt(mom2/mom0)
      maps = {'continuum': avcont, 'linesum': mom0,
              'mean': vmean.to(u.km/u.s).value, 'sigma': vsig.to(u.km/u.s).value}

      # Save an average spectrum as well
      nwinout = kout2 - kout1
      _, _, winwavsout = wcube.all_pix2world([0]*nwinout, [0]*nwinout, np.arange(kout1, kout2), 0)
      winvelsout = waves2vels(winwavsout*u.m.to(u.Angstrom), wav, helio_hdr, observatory='VLT4')

      # Just select region to SW of Trap
      xslice = slice(900, 1400)
      yslice = slice(400, 900)
      spec = {
          'vhel': winvelsout.to(u.km/u.s),
          'wav': winwavsout*u.m.to(u.Angstrom),
          'flux': np.nanmean(cube[kout1:kout2, yslice, xslice], axis=(1, 2)),
          'cont': np.nanmean(avcont[yslice, xslice])*np.ones(nwinout),
      }

      return maps, spec


  for row in linetab:
      print(row['Ion'], row['wav0'])
      save_linemap_files(row['wav0'], sanitize_string(row['Ion']),
                         usecont=[row['blue cont'], row['red cont']])

#+END_SRC

#+BEGIN_SRC sh :results silent
mkdir LineMaps
#+END_SRC

Test it out in a shell
#+BEGIN_SRC sh :eval no
  python extract-em-line.py
#+END_SRC

Check out the heliocentric correction
#+BEGIN_SRC python :results output
  from __future__ import print_function
  import sys
  from astropy.io import fits
  sys.path.append('/Users/will/Dropbox/OrionWest/')
  from helio_utils import helio_topo_from_header

  hdr = fits.open('muse-hr-window-wfc3-f656n.fits')[0].header
  print(helio_topo_from_header(hdr, observatory='VLT4'))
#+END_SRC

#+RESULTS:
: -16.217273731
*** 

#+BEGIN_SRC python :tangle extract-em-line-fuzz.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.table import Table
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy import units as u
  from misc_utils import sanitize_string
  sys.path.append('/Users/will/Dropbox/OrionWest/')
  from helio_utils import waves2vels

  linetab = Table.read('basic-line-list.tab', format='ascii.tab')
  wavsectab = Table.read('wavsec-startwavs.tab', format='ascii.tab')

  def find_wavsec(wav):
      """Which wavsec chunk is this wavelength in"""
      return wavsectab['Section'][wav > wavsectab['CRVAL3']].max() 


  def save_linemap_files(wav, species, mapdir='LineMaps', usecont=[1, 1]):
      wavsec = find_wavsec(wav)
      wavsec_blue = find_wavsec(wav - 8.0)
      wavsec_red = find_wavsec(wav + 8.0)
      if (wavsec_blue != wavsec) or (wavsec_red != wavsec):
          print('Uh, oh - line straddles wavsecs', wavsec_blue, wavsec, wavsec_red)
          if 5000.0 < wav < 6000.0:
              print('But luckily we can use F547M window instead')
              fn = 'muse-hr-window-wfc3-f547m.fits'
          else:
              sys.exit('Unable to find a cube that contains wavelength range - sorry!')
      else:
          fn = 'muse-hr-data-wavsec{}.fits'.format(wavsec)
      hdulist = fits.open(fn)
      hdu = hdulist['DATA']

      # Read in variance for fuzzing
      vfn = 'BigFiles/' + fn.replace('data', 'variance')
      variance = fits.open(fn)['ERR'].data

      w = WCS(hdu.header)
      helio_hdr = fits.open('muse-hr-window-wfc3-f656n.fits')[0].header
      maps, spec =  extract_line_maps(wav, hdu.data, variance, w, helio_hdr, usecont)
      wavid = str(int(wav+0.5))
      # Save the maps to FITS file 
      for mapid, mapdata in maps.items():
          mhdu = fits.PrimaryHDU(header=w.celestial.to_header(), data=mapdata)
          mname = '{}/{}-{}-{}.fits'.format(mapdir, mapid, species, wavid)
          mhdu.writeto(mname, clobber=True)
      sname = '{}/spec1d-{}-{}.tab'.format(mapdir, species, wavid)
      # And save the spectrum to TSV file
      Table(spec).write(sname, format='ascii.tab')

  def extract_line_maps(wav, cube, variance, wcube, helio_hdr,
                        usecont=[1, 1], dwav=4.0, dwavcont=8.0):
      """Extract line moments and continuum"""

      # outer range is wav +/- dwavcont
      wavs = (wav + dwavcont*np.array([-1, 1]))*u.Angstrom.to(u.m)
      _, _, (kout1, kout2) = wcube.all_world2pix([0, 0], [0, 0], wavs, 0)
      kout1, kout2 = int(kout1), int(kout2) + 2

      # inner range is wav +/- dwav
      wavs = (wav + dwav*np.array([-1, 1]))*u.Angstrom.to(u.m)
      _, _, (kin1, kin2) = wcube.all_world2pix([0, 0], [0, 0], wavs, 0)
      kin1, kin2 = int(kin1), int(kin2) + 2

      # find average continuum
      cont1 = np.nanmean(cube[kout1:kin1, :, :], axis=0)
      cont2 = np.nanmean(cube[kin2:kout2, :, :], axis=0)
      # Maybe don't use the continuum on one side (if contaminated)
      wt1, wt2 = usecont          
      avcont = (wt1*cont1 + wt2*cont2)/(wt1 + wt2)

      # Subtract to get pure line window
      linewin = cube[kin1:kin2, :, :] - avcont[None, :, :]
      # Now find moments
      nwin = kin2 - kin1
      _, _, winwavs = wcube.all_pix2world([0]*nwin, [0]*nwin, np.arange(kin1, kin2), 0)
      # Convert wavelengths to velocities
      winvels = waves2vels(winwavs*u.m.to(u.Angstrom), wav, helio_hdr, observatory='VLT4')
      mom0 = linewin.sum(axis=0)
      mom1 = np.sum(linewin*winvels[:, None, None], axis=0)
      vmean = mom1/mom0
      mom2 = np.sum(linewin*(winvels[:, None, None] - vmean)**2, axis=0)
      vsig = np.sqrt(mom2/mom0)
      maps = {'continuum': avcont, 'linesum': mom0,
              'mean': vmean.to(u.km/u.s).value, 'sigma': vsig.to(u.km/u.s).value}

      # Save an average spectrum as well
      nwinout = kout2 - kout1
      _, _, winwavsout = wcube.all_pix2world([0]*nwinout, [0]*nwinout, np.arange(kout1, kout2), 0)
      winvelsout = waves2vels(winwavsout*u.m.to(u.Angstrom), wav, helio_hdr, observatory='VLT4')

      # Just select region to SW of Trap
      xslice = slice(900, 1400)
      yslice = slice(400, 900)
      spec = {
          'vhel': winvelsout.to(u.km/u.s),
          'wav': winwavsout*u.m.to(u.Angstrom),
          'flux': np.nanmean(cube[kout1:kout2, yslice, xslice], axis=(1, 2)),
          'cont': np.nanmean(avcont[yslice, xslice])*np.ones(nwinout),
      }

      return maps, spec


  for row in linetab:
      print(row['Ion'], row['wav0'])
      save_linemap_files(row['wav0'], sanitize_string(row['Ion']),
                         usecont=[row['blue cont'], row['red cont']])


#+END_SRC



** Plot the average spectrum for each line
#+BEGIN_SRC python :tangle plot-em-line-spec.py
  from astropy.table import Table
  from misc_utils import sanitize_string
  from matplotlib import pyplot as plt
  import seaborn as sns

  linetab = Table.read('basic-line-list.tab', format='ascii.tab')

  for row in linetab:
      wav = row['wav0']
      wavid = str(int(wav+0.5))
      species = sanitize_string(row['Ion'])
      sname = 'Linemaps/spec1d-{}-{}.tab'.format(species, wavid)
      spec = Table.read(sname, format='ascii.tab')
      for xkey, xlabel in [['vhel', 'Heliocentric velocity, km/s'],
                           ['wav', 'Observed air wavelength, Angstrom']]:
          fig, ax = plt.subplots(1, 1)
          ax.plot(spec[xkey], spec['flux'])
          ax.plot(spec[xkey], spec['cont'])
          if xkey == 'wav':
              ax.set_xlim(row['wav0']-8.0, row['wav0']+8.0)
          else:
              ax.set_xlim(-300.0, 300.0)
          ax.set_ylim(0.0, None)
          ax.set_xlabel(xlabel)
          ax.set_ylabel('Mean flux per pixel')
          ax.set_title('{} {:.2f}'.format(row['Ion'], row['wav0']))
          fig.set_size_inches(5, 5)
          fig.savefig(sname.replace('.tab', '-{}.pdf'.format(xkey)))
          del(fig)
          del(ax)

#+END_SRC

#+BEGIN_SRC sh :results silent
python plot-em-line-spec.py
#+END_SRC

Look at spectra on heliocentric velocity scale
#+BEGIN_SRC sh
open LineMaps/spec1d*-vhel.pdf
#+END_SRC

#+RESULTS:

Look at spectra on wavelength scale
#+BEGIN_SRC sh
open LineMaps/spec1d*-wav.pdf
#+END_SRC

#+RESULTS:

** TODO Complex method with Gaussian fits
+ This is necessasry for blended lines


* MUSE spectra as a check on fidelity of filter-derived line ratios
** Calculate MUSE line ratios dierctly from emission line maps
Note that [[id:125BB238-D032-4FAD-B6DA-FBFB14DAD3AF][Ratio of multibin maps]] has superseded this for most practical purposes
#+BEGIN_SRC python :tangle muse_line_ratio.py
  from __future__ import print_function
  import sys
  from astropy.io import fits
  def save_line_ratio_map(line1, line2, prefix='linesum', suffix='', mapdir='LineMaps'):
      fn1 = '{}/{}-{}{}.fits'.format(mapdir, prefix, line1, suffix)
      fn2 = '{}/{}-{}{}.fits'.format(mapdir, prefix, line2, suffix)
      print(fn1, fn2)
      hdu1 = fits.open(fn1)[0]
      if hdu1.data is None:
          hdu1 = fits.open(fn1)[1]
      hdu2 = fits.open(fn2)[0]
      if hdu2.data is None:
          hdu2 = fits.open(fn2)[1]
      wav1 = line1.split('-')[-1]
      wav2 = line2.split('-')[-1]
      hdu1.data /= hdu2.data
      if prefix == 'linesum':
          hdu1.writeto('{}/ratio-{}-{}{}.fits'.format(mapdir, wav1, wav2, suffix), clobber=True)
      else:
          hdu1.writeto('{}/ratio-{}-{}-{}.fits'.format(mapdir, prefix, wav1, wav2, suffix), clobber=True)

  if __name__ == '__main__':
      try:
          line1 = sys.argv[1]
          line2 = sys.argv[2]
      except IndexError:
          sys.exit('Usage: {} LINE1 LINE2 [PREFIX] [SUFFIX]'.format(sys.argv[0]))

      try:
          prefix = sys.argv[3]
      except IndexError:
          prefix = 'linesum'

      try:
          suffix = '-' + sys.argv[4]
      except IndexError:
          suffix = ''

      save_line_ratio_map(line1, line2, prefix, suffix)
        

#+END_SRC

S III ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py S_III-6312 S_III-9069
#+END_SRC

Cl III ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py Cl_III-5538 Cl_III-5518
#+END_SRC

N II ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py N_II-5755 N_II-6583
#+END_SRC

S II ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py S_II-6716 S_II-6731
#+END_SRC

Balmer decrement
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py H_I-6563 H_I-4861
#+END_SRC

Balmer decrement upside down for good measure
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py H_I-4861 H_I-6563
#+END_SRC

Paschen-Balmer decrement
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py  H_I-9229 H_I-6563
#+END_SRC

And other way up
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py  H_I-6563 H_I-9229
#+END_SRC

Paschen-Paschen decrement
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py  H_I-8545 H_I-9229
python muse_line_ratio.py  H_I-8598 H_I-9229
python muse_line_ratio.py  H_I-8750 H_I-9229
python muse_line_ratio.py  H_I-8863 H_I-9229
python muse_line_ratio.py  H_I-9015 H_I-9229
#+END_SRC

N II sanity check
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py N_II-6548 N_II-6583
#+END_SRC

O III sanity check
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py O_III-4959 O_III-5007
#+END_SRC

O II red lines
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py O_II-7318 O_II-7330
#+END_SRC

He I ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py He_I-5876 He_I-6678
#+END_SRC

Ar III line ratio
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py Ar_III-7136 Ar_III-7751
#+END_SRC

*** Continuum ratios to see spatial variations in slope

This one doesn't work because of contamination by Balmer line wings
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py H_I-4861 H_I-6563 continuum
#+END_SRC

This one is the best - blue side of 5755
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py Fe_III-4658 N_II-5755 continuum
#+END_SRC

And this one covers red side of 5755
#+BEGIN_SRC sh :results silent
python muse_line_ratio.py N_II-5755 S_II-6731 continuum
#+END_SRC

+ It looks like these ratios do correlate well with equivalent width
  + But that remains to be tested
+ Also should have secondary correlation with reddening
  + But that is not so apparent
    + At least not for the highest extinction, where we seem to have bluer spectra
    + But for the brightest parts, we do maybe have redder continuum where extinction is higher




** Calculate MUSE line ratio maps indirectly from synthetic filters
:PROPERTIES:
:ID:       385E5413-D978-4DE6-98C2-BC893905316B
:END:
+ We start from the =muse-hr-image-wfc3-f*.fits= maps
+ These were created using the nominal throughputs, so we need to back transform them using the same nominal throughputs
+ We do this using nebulio
+ [2015-10-20 Tue] Also, take ratio with the true line ratio
#+BEGIN_SRC sh 
mkdir NebulioMUSE
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :tangle muse-nebulio-line-ratios.py
  from __future__ import print_function
  from misc_utils import sanitize_string
  from astropy.io import fits
  import nebulio
  print(nebulio.__version__)

  # Mean and std of the color terms ktwiddle
  # This is copied from ratio-sensitivity-nebulio.py in the Tsquared folder
  COLOR_TERMS_MEAN_SIG = {
      "FQ674N": (1.00, 0.10), 
      "F673N":  (1.00, 0.10), 
      "FQ672N": (0.99, 0.10), 
      "F658N":  (1.04, 0.11), 
      "F656N":  (1.04, 0.11), 
      "FQ575N": (0.95, 0.03), 
      "F547M":  (1.03, 0.01), 
      "F502N":  (1.10, -0.04), 
      "F487N":  (1.06, -0.06), 
  #    "F487N":  (1.65, -0.06), 
      "FQ437N": (1.41, -0.13), 
      "FQ436N": (1.87, -0.08), 
  }
  def get_color_term(fname="FQ575N", kshift=0.0):
      """Return color term for filter `fname`, shifted `kshift` stdevs from mean"""
      mean, sigma = COLOR_TERMS_MEAN_SIG[fname]
      return mean + kshift*sigma

  filtersets = {
      "5755-6583": {"line1": "[N II] 5755", "line2": "[N II] 6583",
                           "I": "FQ575N", "II": "F658N", "III": "F547M"},
      "6716-6731": {"line1": "[S II] 6716", "line2": "[S II] 6731",
                           "I": "FQ672N", "II": "FQ674N", "III": "F547M"}, 
      "6716-6731-N": {"line1": "[S II] 6716", "line2": "[S II] 6731",
                           "I": "FQ672N", "II": "FQ674N", "III": "F673N"}, 
      "4861-6563": {"line1": "H I 4861", "line2": "H I 6563",
                           "I": "F487N", "II": "F656N", "III": "F547M"},
  }


  def get_fits_data(fn='FQ575N'):
      hdu = fits.open('muse-hr-image-wfc3-{}.fits'.format(fn.lower()))['DATA']
      return hdu.data

  def get_fits_header(fn='FQ575N'):
      hdu = fits.open('muse-hr-image-wfc3-{}.fits'.format(fn.lower()))['DATA']
      return hdu.header

  heliocentric_correction = -16.2
  default_velocity =  25.0 + heliocentric_correction
  default_width = 20.0

  for ratio_name, filterset in filtersets.items():
      FI, FII, FIII = [filterset[J] for J in ("I", "II", "III")]
      print(FI, FII, FIII)
      RI = get_fits_data(FI)
      RII = get_fits_data(FII)
      RIII = get_fits_data(FIII)
      print(RIII[::100, ::100])
      lineids = filterset['line1'], filterset['line2']
      bpnames = ['wfc3,uvis1,' + F for F in (FI, FII, FIII)]
      fset = nebulio.Filterset(bpnames, lineids,
                               velocity=default_velocity, fwhm_kms=default_width)
      kI = get_color_term(FI)/get_color_term(FIII)
      kII = get_color_term(FII)/get_color_term(FIII)
      print('Color terms:', kI ,kII)
      ratio = fset.find_line_ratio(rates=[RI, RII, RIII], colors=(kI, kII), naive=False)
      ratio_naive = fset.find_line_ratio(rates=[RI, RII, RIII], colors=(kI, kII), naive=True)
      # And if we just ignore the color terms
      ratio_flat = fset.find_line_ratio(rates=[RI, RII, RIII], colors=(1.0, 1.0), naive=False)

      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio)
      outhdu.writeto(
          'NebulioMUSE/synthetic-ratio-{}.fits'.format(ratio_name),
          clobber=True)

      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio_naive)
      outhdu.writeto(
          'NebulioMUSE/synthetic-naive-ratio-{}.fits'.format(ratio_name),
          clobber=True)

      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio_flat)
      outhdu.writeto(
          'NebulioMUSE/synthetic-flat-ratio-{}.fits'.format(ratio_name),
          clobber=True)

      # Take ratio of ratios between simulated and true
      # Ignore anything after the second dash in finding the true ratio name
      ratio_name_true = '-'.join(ratio_name.split('-')[:2])
      fn_true = 'LineMaps/ratio-{}.fits'.format(ratio_name_true)
      ratio_true = fits.open(fn_true)[0].data
      ratio_of_ratios = ratio/ratio_true
      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio_of_ratios)
      outhdu.writeto(
          'NebulioMUSE/synthetic-over-true-ratio-{}.fits'.format(ratio_name),
          clobber=True)
      # And the same for the naive/true
      ratio_of_ratios = ratio_naive/ratio_true
      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio_of_ratios)
      outhdu.writeto(
          'NebulioMUSE/synthetic-naive-over-true-ratio-{}.fits'.format(ratio_name),
          clobber=True)
      # And the same for the flat/true
      ratio_of_ratios = ratio_flat/ratio_true
      outhdu = fits.PrimaryHDU(header=get_fits_header(), data=ratio_of_ratios)
      outhdu.writeto(
          'NebulioMUSE/synthetic-flat-over-true-ratio-{}.fits'.format(ratio_name),
          clobber=True)
          
#+END_SRC

#+BEGIN_SRC sh
export PYTHON_CDBS=~/Dropbox/CDBS
python muse-nebulio-line-ratios.py 1>&2
#+END_SRC

#+RESULTS:

+ Mostly looks OK
+ [X] But there is a strange problem with hb/ha
  + The synthetic value comes out too large by about 5 to 10%
  + I tried fiddling with the ktwiddle color terms, but that didn't seem to work
  + [2015-10-22 Thu] All sorted now - it was a problem with which CDBS I used

** DONE Two-D histogram of MUSE synthetic filter vs MUSE true line ratios
CLOSED: [2015-10-22 Thu 17:21]
#+BEGIN_SRC python :tangle histo-muse-ratios.py
  from __future__ import print_function
  import numpy as np
  from astropy.io import fits
  from astropy.convolution import convolve, Gaussian2DKernel
  from matplotlib import pyplot as plt
  import seaborn as sns
  from specplot1d_utils import plot_1d_spec_from_fits


  plotpars = {
      '6716-6731': {'line1': '[S II] 6716', 'line2': '[S II] 6731',
                    'min': 0.4, 'max': 1.1},
      '6716-6731-N': {'line1': '[S II] 6716', 'line2': '[S II] 6731',
                    'min': 0.4, 'max': 1.1},
      '5755-6583': {'line1': '[N II] 5755', 'line2': '[N II] 6583',
                    'min': 0.0, 'max': 0.04},
      '4861-6563': {'line1': 'H I 4861', 'line2': 'H I 6563',
                    'min': 0.15, 'max': 0.35},
    }

  titles_from_extra = {
      '': 'Fully continuum-corrected with color terms',
      '-naive': 'Uncorrected for continuum',
      '-flat': 'Partially continuum-corrected but without color terms',
  }

  GAMMA = 1.0

  cmap = sns.light_palette((260, 50, 30), input="husl", as_cmap=True)
  # cmap = plt.cm.gray_r

  def histogram_ratio_images(ratio_name, pars, extra=''):
      ratio_name_true = '-'.join(ratio_name.split('-')[:2])
      fn_true = 'LineMaps/ratio-{}.fits'.format(ratio_name_true)
      fn_syn = 'NebulioMUSE/synthetic{}-ratio-{}.fits'.format(extra, ratio_name)
      pltname = 'NebulioMUSE/synthetic{}-vs-true-calib-{}.pdf'.format(extra, ratio_name)
      hdu_true = fits.open(fn_true)[0]
      hdu_syn = fits.open(fn_syn)[0]
      # Flux of a strong line to weight the pixels
      hduf = fits.open('LineMaps/linesum-N_II-6583.fits')[0]
      x, y, w = hdu_true.data, hdu_syn.data, hduf.data
      xmin, xmax = ymin, ymax = pars['min'], pars['max']
      # mask out silly values
      m = np.isfinite(x) & np.isfinite(y/x) & (np.abs(np.log10(y/x)) < 1.0)
      H, xedges, yedges = np.histogram2d(x[m], y[m], 400,
                                         [[xmin, xmax], [ymin, ymax]],
                                         weights=w[m])
      fig, ax = plt.subplots(1, 1)
      ax.imshow((H.T)**(1.0/GAMMA), extent=[xmin, xmax, ymin, ymax],
                interpolation='nearest', aspect='auto', origin='lower', 
                cmap=cmap, alpha=1.0)
      ax.plot([xmin, xmax], [xmin, xmax], '-', alpha=1.0,
              lw=1, c='r', label=None)
      ax.set_xlabel(
          'MUSE spectrum-derived line ratio: {} / {}'.format(
              pars['line1'], pars['line2']))
      ax.set_ylabel(
          'MUSE synthetic WFC3 filter-derived line ratio: {} / {}'.format(
              pars['line1'], pars['line2']))
      ax.set_xlim(xmin, xmax)
      ax.set_ylim(ymin, ymax)
      ax.text(0.3, 0.05, titles_from_extra[extra], transform=ax.transAxes)

      fig.set_size_inches(7, 7)
      fig.savefig(pltname)

      return pltname


  if __name__ == '__main__':
      for ratio_name, pars in plotpars.items():
          for extra in '', '-naive', '-flat':
              print(histogram_ratio_images(ratio_name, pars, extra))

#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh :results verbatim
python histo-muse-ratios.py
#+END_SRC

#+RESULTS:
#+begin_example
NebulioMUSE/synthetic-vs-true-calib-6716-6731.pdf
NebulioMUSE/synthetic-naive-vs-true-calib-6716-6731.pdf
NebulioMUSE/synthetic-flat-vs-true-calib-6716-6731.pdf
NebulioMUSE/synthetic-vs-true-calib-6716-6731-N.pdf
NebulioMUSE/synthetic-naive-vs-true-calib-6716-6731-N.pdf
NebulioMUSE/synthetic-flat-vs-true-calib-6716-6731-N.pdf
NebulioMUSE/synthetic-vs-true-calib-4861-6563.pdf
NebulioMUSE/synthetic-naive-vs-true-calib-4861-6563.pdf
NebulioMUSE/synthetic-flat-vs-true-calib-4861-6563.pdf
NebulioMUSE/synthetic-vs-true-calib-5755-6583.pdf
NebulioMUSE/synthetic-naive-vs-true-calib-5755-6583.pdf
NebulioMUSE/synthetic-flat-vs-true-calib-5755-6583.pdf
#+end_example

#+BEGIN_SRC sh :result silent
open NebulioMUSE/synthetic-vs-true-calib-*.pdf
open NebulioMUSE/synthetic-naive-vs-true-calib-*.pdf
open NebulioMUSE/synthetic-flat-vs-true-calib-*.pdf
#+END_SRC

#+RESULTS:

#+RESULTS

** DONE Now compare synthetic filter-derived ratios with real WFC3 filter-derived ones
CLOSED: [2015-10-22 Thu 17:21]
:LOGBOOK:
CLOCK: [2015-10-21 Wed 21:19]--[2015-10-22 Thu 00:27] =>  3:08
:END:
+ [2015-10-21 Wed] I have using DS9
  + MUSE :: synthetic-ratio-5755-6583.fits
  + WFC3 :: newratio-5755-6583.fits
+ This works tolerably well now


*** Old comments
+ They are significantly different
  + MUSE synthetic map has median ratio < 0.15 in faint parts
  + WFC3 map has median ratio > 0.15 in faint parts
+ But the real and synthetic filter images should be the same
  + If we look at =wfc3-over-muse-calib-ratio-F*.fits= then we find
    + F575N and F658N are fine
    + But F547M shows some discrepancies
      + Over most of the field the ratio is 0.9 rather than 1
      + Although I had interpreted that as a shift of origin
      + I think that is partly due to the hump of scattered light that comes down from Trapezium
    + F656N also shows a bit of a discrepancy
      + The ratio is 1.03 in the brighter part of the sweet spot (which is what we adopted from the straight line cuts)
      + But is more like 104 to 1.05 in the fainter parts
    + F673N is prety good at 1.0 apart from the hump
      + Not much justification for the 0.97, except for at the top, which is outsid ethe sweetspot
    + FQ672N looks like it has a gradient from 1.0 to 1.1 from the top left to bottom right, parallel to the chip - maybe there is a flat field error
      + We had interpreted this as an offset
      + But that does sort of fit too
    + FQ674N does not have this problem
+ *What would be the consequences of overestimating F547M?*
  + Means true continuum is higher than we had thought
  + So we should subtract more from the FQ575N filter, which will bring down the nii ratio
  + Which is what we want!

** Conclusions on spectra vs filters comparison with MUSE
1. In general it works very well
2. There are small residual correlations betwen line ratios and continuum color, which means the relations don't quite have unit slope
   - In the case of Hb/Ha this is probably due to the fact that continuum is reddened the same as the lines are - we could even correct for that
   - That same correction could even then be applied to the other filters
3. The [S II] ratio is best determined using the F673N filter to get the continuum
4. The [N II] ratio has a lot of noise, but then we knew that already
5. There was some strangeness with Hb/Ha
   - I had to bump up the color term a lot
   - At first I thought this was justified because the continuum looked blue
     - Even though the fig I had calculated from ODH said not
   - But now I realise that the relevant slope is in \lambda F_{\lambda}
     - Which is much flatter
   - So I am a bit confused, but going to move on anyhow

* Calibration of WFC3 filter using MUSE cube
:LOGBOOK:
CLOCK: [2015-10-07 Wed 09:58]--[2015-10-07 Wed 11:58] =>  2:00
:END:
+ The interesting sections are wavsec0 to wavsec3

** Extract subsets of the full cubes

*** Transposed cubes
+ These are taken from the section cubes that I made [[id:C2108CD1-EF28-4F63-9CA1-B7F9DA59C450][down here]]
  + Origina axis order is RA, Dec, Wav
+ They will look like longslit spectra in DS9 - at least that is the idea

**** TODO Stack of horizontal slits: Wav, RA, Dec
+ 1 2 3 -> 3 1 2
#+BEGIN_SRC sh :results verbatim
  MDIR=~/Source/Montage/bin
  $MDIR/mTranspose muse-hr-data-wavsec0.fits muse-hr-hslit-stack-wavsec0.fits 3 1 2
#+END_SRC

#+RESULTS:

+ Note that this takes a long time to run - even longer on my laptop
+ Best to do it in a terminal rather than with babel
+ They are too big (17GB each), so I have moved tham to a =BigFiles/= folder, which I am not synching with my laptop, only with hypatia

**** TODO Stack of vertical slits: Wav, Dec, RA
+ 1 2 3 -> 3 2 1

**** Bin them up to make them easier to use

***** DONE 1 arcsec pixels: 5x5 binning in RA and Dec
CLOSED: [2015-10-16 Fri 08:42]
+ First, work directly on the original cube sections
+ FITS order is RA, Dec, Wav
+ Python order is Wav, Dec, RA
+ Original NY, NX is 1476, 1766
  + If we chop off just 1 pixel on each axis, then we are divisible by 5
+ Work on one image at time to simplify things and reduce memory footprint
#+BEGIN_SRC python :tangle rebin_datacube.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits

  def rebin_xyimage(im, mx=5, my=5):
      ny, nx = im.shape
      # Shape of new rebinned array
      nny, nnx = ny//my, nx//mx
      # Shave a bit off original array so shape is multiple of m
      # And then concertina each axis to be 4-dimensional
      im4d = im[:nny*my, :nnx*mx].reshape((nny, my, nnx, mx))
      # Average along the mx, my axes
      return np.nansum(im4d, axis=(1, 3))


  def rebin_hdu(hdu, m=(5, 5)):
      mx, my = m                  # FITS axis order
      nv, ny, nx = hdu.data.shape  # Python axis order
      nny, nnx = ny//my, nx//mx
      newdata = np.empty((nv, nny, nnx))
      for k in range(nv):
          print('Rebinning plane {}/{}'.format(k+1, nv))
          newdata[k] = rebin_xyimage(hdu.data[k], mx, my)
      newhdu = fits.PrimaryHDU(header=hdu.header, data=newdata)
      # New pixel deltas are bigger
      if 'CDELT1' in newhdu.header:
          newhdu.header['CDELT1'] *= mx
          newhdu.header['CDELT2'] *= my
      else:
          # assume no rotation
          newhdu.header['CD1_1'] *= mx
          newhdu.header['CD2_2'] *= my
        
           # pix=0.5 is left edge of first pixel
      newhdu.header['CRPIX1'] = 0.5 + (newhdu.header['CRPIX1'] - 0.5)/mx
      newhdu.header['CRPIX2'] = 0.5 + (newhdu.header['CRPIX2'] - 0.5)/my

      return newhdu

  if __name__ == '__main__':
      try:
          infilename = sys.argv[1]
          m = int(sys.argv[2]), int(sys.argv[3])
      except IndexError:
          sys.exit('Usage: {} FITSFILE BINX BINY'.format(sys.argv[0]))

      hdu = fits.open(infilename)['DATA']
      newsuffix = '-rebin{:02d}x{:02d}.fits'.format(*m)
      outfilename = infilename.replace('.fits', newsuffix)
      rebin_hdu(hdu, m).writeto(outfilename, clobber=True)

#+END_SRC

+ These should all be run in an interactive shell
+ First, test it with a small file
  #+BEGIN_SRC sh :eval no
  python rebin_datacube.py muse-hr-window-wfc3-fq575n.fits 5 5
  #+END_SRC
+ Then do all the big sections
  #+BEGIN_SRC sh :eval no :tangle rebin-all-wavsecs.sh
    for i in $(seq 7); do
        python rebin_datacube.py muse-hr-data-wavsec$i.fits 5 5
    done
  #+END_SRC


***** Glue all the wavsecs back together again to make one big spectrum
If we demote the data arrays to 32 bit reals, then this should be still less than 2GB for the 5x5 spatial binning

#+BEGIN_SRC python :tangle reassemble-fullcube.py
  from __future__ import print_function
  import numpy as np
  from astropy.io import fits

  def reassemble(nsec=8, suffix='rebin05x05'):
      template = 'muse-hr-data-wavsec{isec}-{suffix}.fits'

      cubes = []
      for isec in range(nsec):
          fn = template.format(isec=isec, suffix=suffix)
          hdulist = fits.open(fn)
          hdu = hdulist[0]
          # The full cube will use the header from the first section
          if isec == 0:
              hdr = hdu.header.copy()
          # Save this section of the cube 
          cubes.append(hdu.data.astype(np.float32))
          print('Section', isec, 'saved')
          hdulist.close()
      newhdu = fits.PrimaryHDU(header=hdr, data=np.concatenate(cubes))
      outfile = 'muse-hr-fullcube-{suffix}.fits'.format(suffix=suffix)
      newhdu.writeto(outfile, clobber=True)
      return outfile

  if __name__ == '__main__':

      print('Reassembling cube ...')
      print('... done:', reassemble())
    
#+END_SRC

Run in interactive shell 
#+BEGIN_SRC sh :eval no
time python reassemble-fullcube.py
#+END_SRC


*** Spectral windows for each WFC3 filter
:PROPERTIES:
:header-args: :python /Users/will/anaconda/envs/py27/bin/python :preamble "from __future__ import print_function" :noweb yes
:END:

+ In principal the calibration can be done with just integrating the spectrum over the filter T reponse.
+ But we really need to fit Gaussians to the lines
+ Note that pysynphot requires Python 2.7
+ Also requires PYSYN_CDBS environment variable to be set
  + On linux server
#+BEGIN_SRC sh
export PYSYN_CDBS=/fs/nil/other0/will/CDBS
#+END_SRC


**** List of HST filters to use
:PROPERTIES:
:TABLE_EXPORT_FILE: all-filters-input.tab
:TABLE_EXPORT_FORMAT: orgtbl-to-tsv
:END:

Export this table to [[file:all-filters-input.tab]] with =C-c t e= after any modification. 

#+name: selected-filters
| Instrument | Filter |
|------------+--------|
| wfc3       | fq436n |
| wfc3       | fq437n |
| wfc3       | f469n  |
| wfc3       | f487n  |
| wfc3       | f502n  |
| wfc3       | f547m  |
| wfc3       | fq575n |
| wfc3       | f656n  |
| wfc3       | f658n  |
| wfc3       | fq672n |
| wfc3       | f673n  |
| wfc3       | fq674n |
|------------+--------|
| wfpc2      | f437n  |
| wfpc2      | f469n  |
| wfpc2      | f487n  |
| wfpc2      | f502n  |
| wfpc2      | f547m  |
| wfpc2      | f631n  |
| wfpc2      | f656n  |
| wfpc2      | f658n  |
| wfpc2      | f673n  |
|------------+--------|
| acs        | f658n  |
| acs        | f660n  |
| acs        | f435w  |
| acs        | f555w  |
| acs        | f775w  |
| acs        | f850lp |


Send all tables to linux server
#+BEGIN_SRC sh :results verbatim
rsync -aPq *.tab nil:/fs/nil/other0/will/orion-muse
#+END_SRC

#+RESULTS:

#+name: bandpass-fullname-function
#+BEGIN_SRC python
  def bp_fullname(instrument, filter_):
      if instrument.lower() == 'wfc3':
          return 'wfc3,uvis1,'+filter_.lower()
      elif instrument.lower() == 'acs':
          return 'acs,wfc1,'+filter_.lower()
      elif instrument.lower() == 'wfpc2':
          return 'wfpc2,'+filter_.lower()
      else:
          raise NotImplementedError('Unknown instrument: ' + instrument)
#+END_SRC


**** DONE [1/1] Print out the mean wavelength and rectangular width of each filter
CLOSED: [2015-10-08 Thu 11:25]
#+name: extract-bandpasses 
#+BEGIN_SRC python :return outtab
  import pysynphot
  from astropy.table import Table
  <<bandpass-fullname-function>>
  float_fmt = '{:.2f}'
  intab = Table.read('all-filters-input.tab', format='ascii.tab')
  outtab = [['Filter', 'Wav0', 'dWav'], None]
  for row in intab:
      fn = bp_fullname(row['Instrument'], row['Filter'])
      bp = pysynphot.ObsBandpass(fn)
      outtab.append([fn, float_fmt.format(bp.avgwave()), float_fmt.format(bp.rectwidth())])
#+END_SRC

#+RESULTS: extract-bandpasses
| Filter            |    Wav0 |    dWav |
|-------------------+---------+---------|
| wfc3,uvis1,fq436n | 4367.22 |   43.36 |
| wfc3,uvis1,fq437n | 4371.09 |   29.99 |
| wfc3,uvis1,f469n  | 4688.14 |   49.67 |
| wfc3,uvis1,f487n  | 4871.42 |   60.41 |
| wfc3,uvis1,f502n  | 5009.71 |   65.27 |
| wfc3,uvis1,f547m  | 5451.37 |  649.89 |
| wfc3,uvis1,fq575n | 5757.87 |   18.37 |
| wfc3,uvis1,f656n  | 6561.44 |   17.65 |
| wfc3,uvis1,f658n  | 6584.91 |   27.55 |
| wfc3,uvis1,fq672n | 6716.62 |   19.37 |
| wfc3,uvis1,f673n  | 6766.04 |  117.78 |
| wfc3,uvis1,fq674n | 6730.77 |   17.63 |
| wfpc2,f437n       | 4369.57 |   31.84 |
| wfpc2,f469n       | 4694.55 |   33.10 |
| wfpc2,f487n       | 4865.48 |   33.93 |
| wfpc2,f502n       | 5013.41 |   35.80 |
| wfpc2,f547m       | 5487.62 |  638.11 |
| wfpc2,f631n       | 6306.45 |   42.14 |
| wfpc2,f656n       | 6563.57 |   28.34 |
| wfpc2,f658n       | 6590.91 |   39.24 |
| wfpc2,f673n       | 6732.30 |   63.31 |
| acs,wfc1,f658n    | 6584.05 |   74.94 |
| acs,wfc1,f660n    | 6599.50 |   35.69 |
| acs,wfc1,f435w    | 4338.43 |  862.30 |
| acs,wfc1,f555w    | 5373.22 | 1124.61 |
| acs,wfc1,f775w    | 7705.71 | 1320.72 |
| acs,wfc1,f850lp   | 9049.59 | 1261.35 |

+ [X] Test that this works on linux server



**** Decomposing the components that go into the throughput curve

This is done in [[file:wfc3-throughput-components.py]]

Use the STScI python install for a change
#+BEGIN_SRC sh :results file :file wfc3-throughput-components.pdf
source ~/.bash_profile
ur_setup
export PYSYN_CDBS=/Users/will/Dropbox/CDBS
python wfc3-throughput-components.py
#+END_SRC

#+RESULTS:
[[file:wfc3-throughput-components.pdf]]

This is a plot of all the components that multiply together to make the filter throughput:
+ hst_ota :: Optical Telescope Assembly.  I think this is the primary mirror efficiency, accounting for fraction of circular area that is obscured by secondary. Roughly constant at about 0.65
+ wfc3_uvis_ccd1 :: Efficiency of CCD, roughly constant at ~ 0.87
  + Note that CCD2 is extremely similar.  The difference is less than 0.5%
+ wfc3_uvis_owin :: Outer window transmission, roughly 0.95
+ wfc3_uvis_cor :: Correction based on white dwarf photometry. Roughly 1.18 but falling to red.
+ wfc3_uvis_mir1 :: Internal camera mirror efficiency, roughly 0.9
+ wfc3_uvis_mir2 :: Another mirror efficiency, roughly 0.9
+ wfc3_uvis_iwin :: Internal window, roughly 0.95
+ wfc3_pom_001 :: Pick Off Mirror (45 deg mirror that diverts light into instrument), roughly 0.88
+ wfc3_uvis_f547m :: The filter itself, roughly 0.85 

Multiplying them all together gives the total transmission of src_calc{0.65 0.87 0.95 1.18 0.9 0.9 0.95 0.88 0.85} {{{results(=0.364878642843=)}}}, which matches what is expected for the total bandpass.


***** DONE Variation with time
CLOSED: [2015-10-13 Tue 09:23]
+ According to [[http://ssb.stsci.edu/pysynphot/docs/appendixb.html#pysynphot-appendixb][Appendix B of the pysynphot docs]] we can ask for the filter throughput for a particular MJD using e.g., 'wfc3,uvis1,f658n,mjd#49486'
+ Today's Julian date is src_calc{julian(<Tue Oct 13, 2015>) - 2400000} {{{results(=57307=)}}}
+ Orion S observations were around MJD=55933
+ Plot various dates in [[file:wfc3-throughput-evolution.py]]
#+BEGIN_SRC sh :results file :file wfc3-throughput-evolution.pdf
source ~/.bash_profile
ur_setup
export PYSYN_CDBS=/Users/will/Dropbox/CDBS
python wfc3-throughput-evolution.py
#+END_SRC

#+RESULTS:
[[file:wfc3-throughput-evolution.pdf]]

Upshot is that there is no discernible difference with time, and also that the Quantum Yield Correction makes no difference at the shortest wavelengths that we are interested in (4700 Angstrom), 

src_python{import sys; return sys.version.split(' ')[0]} {{{results(=2.7.10=)}}} 

**** TODO Converting surface brightness to predicted counts
+ Note that =bp.primary_area= is given as 45238.93416, which must be in sq cm.  This is same as src_calc{pi*(120)**2} {{{results(=45238.9342117=)}}} 
+ The units of the muse data is given as '10**(-20)*erg/s/cm**2/Angstrom'
  + This must be per pixel, I assume
  + Each pixel is 0.2 arcsec square, so this is src_calc{(0.2/206265)**2} {{{results(=9.40175455274e-13=)}}} steradian
+ [ ] We have summed this in wavelength, but we really should have multiplied by lambda first to convert from energy to photon units
  + And while we are at it we can use the C_{WFC3} to put it in electron/s



**** Air to vacuum wavelength conversion
+ This depends on refractive index of air, given by the following function
+ To convert air -> vacuum we multiply the wavelengths by the refractive index
+ 

#+name: air-refractive-index
#+BEGIN_SRC python
  from astropy import units as u
  def air_refractive_index(wav):
      """Equation (65) of Greisen et al 2006 for the refractive index of air
  at STP.  Input wavelength 'wav' should be in microns or in any
  'astropy.units' unit. It does not matter if 'wav' is on air or vacuum
  scale

      """
      try:
          # Convert to microns if necessary
          wavm = wav.to(u.micron).value
      except AttributeError:
          # Assume already in microns
          wavm = wav
      return 1.0 + 1e-6*(287.6155 + 1.62887/wavm**2 + 0.01360/wavm**4)

#+END_SRC
**** TODO [5/5] Process spectral windows for each filter
+ This could be the last step that we would have to run on the server
+ If the files are small enough then they can be copied over to the macs
+ Each of the following snippets is run interactively on the server
***** DONE Imports
CLOSED: [2015-10-08 Thu 12:00]
#+name: astro-imports
#+BEGIN_SRC python
  from astropy.io import fits
  from astropy import wcs
  from astropy.table import Table
  import pysynphot
  import numpy as np
#+END_SRC
***** DONE Read FITS cube
CLOSED: [2015-10-08 Thu 12:00]
#+BEGIN_SRC python
  hdulist = fits.open('DATA/DATACUBEFINALuser_20140216T010259_78380e1d.fits')
#+END_SRC
***** DONE Set up a vacuum wavelength scale
CLOSED: [2015-10-08 Thu 14:01]
#+namer: setup-wavs
#+BEGIN_SRC python
  <<air-refractive-index>>
  w = wcs.WCS(hdulist['DATA'].header)
  NV, NY, NX = hdulist['DATA'].data.shape
  # construct array of observed air wavelengths (at image center to be safe)
  _, _, wavs = w.all_pix2world([NX/2]*NV, [NY/2]*NV, np.arange(NV), 0) 
  # Make dimensional
  wavs *= u.m
  # Convert to vacuum scale
  wavs *= air_refractive_index(wavs)
#+END_SRC
***** DONE Read in the table of filters
CLOSED: [2015-10-08 Thu 14:08]
#+BEGIN_SRC python
  intab = Table.read('all-filters-input.tab', format='ascii.tab')
#+END_SRC
***** DONE Extract the windows for each filter
CLOSED: [2015-10-12 Mon 09:18]
#+BEGIN_SRC python
  <<bandpass-fullname-function>>
  for row in intab:
      bpname = bp_fullname(row['Instrument'], row['Filter'])
      bp = pysynphot.ObsBandpass(bpname)
      # extend a full rectwidth either side of the average wavelength to fit it all in
      wav_window = bp.avgwave() + bp.rectwidth()*np.array([-1, 1])
      # Add in the units (all are in Angstrom I hope)
      assert bp.waveunits.name == 'angstrom'
      wav_window *= u.Angstrom
      # convert to air wavelengths to agree with the WCS
      wav_window /= air_refractive_index(wav_window)
      # Now convert to fractional pixel coordinates
      _, _, [k1, k2] = w.all_world2pix([0, 0], [0, 0], wav_window.to(u.m), 0)
      # smallest slice that covers the window
      wavslice = slice(int(k1), int(k2) + 2)
      # tuple of slices for the 3 cube axes (in numpy array order: V, Y, X)
      cubeslices = [wavslice, slice(None, None), slice(None, None)]

      newhdr = hdulist['DATA'].header.copy()
      newhdr.update(w.slice(cubeslices).to_header())

      # Make a new HDUlist for the windowed spectrum and write it out
      fits.HDUList(
          [fits.PrimaryHDU(header=hdulist[0].header, data=None),
           fits.ImageHDU(header=newhdr, data=hdulist['DATA'].data[cubeslices])
          ]
      ).writeto('muse-hr-window-{}-{}.fits'.format(row['Instrument'], row['Filter']), clobber=True)
#+END_SRC
**** Cleaning up the window FITS files for DS9
:PROPERTIES:
:ID:       45AB8659-4D07-4EE5-A3DC-FECF9C10833D
:END:
For some reason, ds9 does not like the wavelength WCS, so we will try and fix it:
+ Put the physical scales in the CDELTi instead of in the PCi_j
+ Put it in angstrom instead of m
+ That's it to start with
#+BEGIN_SRC python :tangle clean_up_wav_wcs.py
  import sys
  from astropy.io import fits
  def clean_up_wav_wcs(filename):
      hdulist = fits.open(filename, mode='update')
      for hdu in hdulist:
          if hdu.header.get('CUNIT3') == 'm':
              # Change to Angstrom
              hdu.header['PC3_3'] *= 1e10
              hdu.header['CRVAL3'] *= 1e10
              hdu.header['CUNIT3'] = 'Angstrom'
              # And move scales to CDELT
              for i in '123':
                  CDELTi = 'CDELT'+i
                  # Sanity check
                  assert hdu.header.get(CDELTi) == 1.0
                  PCi_j = 'PC{0}_{0}'.format(i)
                  hdu.header[CDELTi], hdu.header[PCi_j] = hdu.header[PCi_j], hdu.header[CDELTi] 
      hdulist.flush()


  if __name__ == '__main__':
      try:
          fn = sys.argv[1]
          clean_up_wav_wcs(fn)
      except IndexError:
          print('Usage:', sys.argv[0], 'FITSFILE')
        
#+END_SRC
Export with =C-u C-c C-v C-t=

Test it on the WFC3 f656n file

#+BEGIN_SRC sh :results silent
python clean_up_wav_wcs.py muse-hr-window-wfc3-fq674n.fits
#+END_SRC

That seemed to work

#+BEGIN_SRC sh :results silent
python clean_up_wav_wcs.py muse-hr-window-wfc3-f487n.fits
#+END_SRC

**** DONE Convert from erg/cm2/s/Angstrom to electron/s
CLOSED: [2015-10-13 Tue 12:50]
:LOGBOOK:
- Note taken on [2015-10-13 Tue 09:58]
:END:
+ The fundamental equation is \(R_{}_j = C_{WFC3 }\int \lambda I_\lambda T_\lambda d\lambda\)
  + Where C_{WFC3 }= 0.0840241 if \lambda is in \AA
+ So, we need to multiply by lambda when we do the flattening
+ Also, we need to get from MUSE's flux-per-pixel to brightness (per-steradian)
  + This means we divide by the MUSE pixel area of 9.40175455274e-13 sr
+ AND we need to multiply by the MUSE bin width in \AA
+ Question is, do we apply this normalization to the =transwin= cubes?
  + Best not, so as to minimze churn of large files on Dropbox

#+name: flux-to-counts
#+BEGIN_SRC python
  from astropy import units as u
  WFC3_CONSTANT = 0.0840241
  MUSE_FLUX_UNITS = 1e-20 
  MUSE_PIXEL_AREA_SR = (0.2*u.arcsec).to(u.radian)**2

#+END_SRC
**** Fold the spectra through each filter to get simulated images
This does not have to be done on the server any more

#+BEGIN_SRC python :tangle filter-flatten.py 
  from __future__ import print_function
  import sys
  <<astro-imports>>
  <<air-refractive-index>>
  <<bandpass-fullname-function>>
  <<flux-to-counts>>

  def bandpass_flatten(instrument, bpname):
      filename = 'muse-hr-window-{}-{}.fits'.format(instrument, bpname)
      hdulist = fits.open(filename)
      hdu = hdulist['DATA']
      w = wcs.WCS(hdu.header)
      NV, NY, NX = hdu.data.shape
      # construct array of observed air wavelengths (at image center to be safe)
      _, _, wavs = w.all_pix2world([NX/2]*NV, [NY/2]*NV, np.arange(NV), 0) 
      # Make dimensional
      wavs *= u.m
      # Convert to vacuum scale
      wavs *= air_refractive_index(wavs)

      # Get bandpass for filter
      fn = bp_fullname(instrument, bpname)
      bp = pysynphot.ObsBandpass(fn)
      # Calculate transmission curve at the observed wavelengths
      T = bp(wavs.to(u.Angstrom).value)
      # Weight by transmission curve and save that
      hdu.data *= T[:, None, None]
      hdulist.writeto(filename.replace('-window-', '-transwin-'), clobber=True)
      # Integrate over wavelength, already weighted by transmission curve. But
      # now need to multiply by wavelength, put in brightness units, and
      # convert to WFC3 electron/s/pixel
      hdu.data *= WFC3_CONSTANT*MUSE_FLUX_UNITS/MUSE_PIXEL_AREA_SR
      hdu.data *= wavs.to(u.Angstrom).value[:, None, None]
      hdu.data = hdu.header['CDELT3']*np.sum(hdu.data, axis=0)
      hdu.header['BUNIT'] = 'electron/s/(0.03962 arcsec)**2'
      hdulist.writeto(filename.replace('-window-', '-image-'), clobber=True)

  if __name__ == '__main__':
      try:
          instrument, bpname = sys.argv[1:]
          bandpass_flatten(instrument, bpname)
      except IndexError:
          print('Usage:', sys.argv[0], 'INSTRUMENT FILTER')
  
#+END_SRC

New example of use, using STSCI python on laptop
#+BEGIN_SRC sh :results silent
source ~/.bash_profile
ur_setup
export PYSYN_CDBS=/Users/will/Dropbox/CDBS
python filter-flatten.py wfc3 fq575n
#+END_SRC


Check the same one using the Anaconda py27 on hypatia, but make sure that we are using the same version of CDBS
#+BEGIN_SRC sh :results silent
source activate py27
export PYSYN_CDBS=/Users/will/Dropbox/CDBS
python filter-flatten.py wfc3 fq575n
#+END_SRC
Exactly the same, which is a heartening.  

Now do it for all the filters
#+BEGIN_SRC sh
  source activate py27
  export PYSYN_CDBS=/Users/will/Dropbox/CDBS
  FILTERS="f469n f487n f502n f547m fq575n f656n f658n fq672n f673n fq674n"
  for f in $FILTERS; do
      echo Flattening $f
      python filter-flatten.py wfc3 $f
  done
#+END_SRC

#+RESULTS:
| Flattening | f469n  |
| Flattening | f487n  |
| Flattening | f502n  |
| Flattening | f547m  |
| Flattening | fq575n |
| Flattening | f656n  |
| Flattening | f658n  |
| Flattening | fq672n |
| Flattening | f673n  |
| Flattening | fq674n |
**** Comparing profiles by eye
:PROPERTIES:
:ID:       B1BF9964-0468-480C-8A10-B1885B5A2006
:END:
+ Took some profiles by eye on WFC3 and MUSE images of F547M
  + Cannot compare them in DS9 because the spatial axis is written in pixels, which are different sizes 
+ [[file:muse-f547m-cut.dat]]
+ [[file:wfc3-f547m-cut.dat]]
** DONE [4/4] Compare the real and predicted count-rate images on a common grid
CLOSED: [2015-10-15 Thu 12:05]
+ We want to put everything on the MUSE pixel grid, since that will make smaller files by a factor of src_calc{(0.2/0.03962)**2} {{{results(=25.4818555174=)}}}
+ We could use
  1. astrodrizzle
     - [[file:~/Dropbox/OrionHST-2012/HST-ACS/acs-ramp-filters.org][acs-ramp-filters.org]]
  2. montage
     - [[https://montage-wrapper.readthedocs.org]]
     - I had already done that in the t-squared [[id:A237AB1D-270E-497F-BB6B-2FD78C43E668][project]]
     - And I hadn't even used the python bindings
*** DONE Check that I have a working Montage installation
CLOSED: [2015-10-14 Wed 09:10]
+ I already have version 3.3 but version 4 is out
+ Cloning from github into [[file:~/Source/Montage/]]
+ Compiled with =make -j8= - that was fast!
*** DONE Testing out Montage
CLOSED: [2015-10-14 Wed 09:10]
#+BEGIN_SRC sh :results verbatim
PATH=$PATH:~/Source/Montage/bin
err=$(mProjectPP --help)
echo $err
#+END_SRC

#+RESULTS:
: [struct stat="ERROR", msg="Usage: mProjectPP [-z factor][-d level][-b border][-s statusfile][-o altout.hdr][-i altin.hdr][-h hdu][-x scale][-w weightfile][-t threshold][-X(expand)] in.fits out.fits template.hdr"]
*** DONE Script to resample WFC3 image onto MUSE grid
CLOSED: [2015-10-14 Wed 09:12]
+ Header for MUSE full frame grid: [[file:muse-full-frame.hdr]]
+ This does not expand the WFC3 image beyond its original borders
  + So we will have to extract a section of the MUSE image for comparison
  + On the other hand, it does maintain the same reference pixel
    + But with different values of CRPIX because the image lower left corner is different
    + So it has the same values of CRVAL
    + This will make it easy to slice the MUSE image
+ Smoothing needs to be improved
  + No smoothing is too little
  + The =s120= images that I already have are too much (this was 1.2 arcsec I assume)
  + In the [[id:2E0AC321-C544-4E65-9D59-9A11F96E94BD][t2 notes]] I calculated FWHM of 4 pixels = 0.8 arcsec
  + Actually 0.7 arcsec was better - this is now done in [[id:0CF5E394-36D0-4589-9E02-93EEDE7CF151][the orion-t2.org notes]]
#+BEGIN_SRC sh :tangle wfc3-resample-to-muse.sh
F=$1
MDIR=~/Source/Montage/bin
TDIR=~/Work/RubinWFC3/Tsquared
$MDIR/mProjectPP -h 0 -X $TDIR/full_${F}-s070.fits wfc3-resample-muse-$F.fits muse-full-frame.hdr
#+END_SRC

Test with a single image
#+BEGIN_SRC sh :results verbatim
time sh wfc3-resample-to-muse.sh F547M 2>&1 
#+END_SRC

#+RESULTS:
: [struct stat="OK", time=3]


Do all of the images
#+BEGIN_SRC sh :results verbatim
  FILTERS="f469n f487n f502n f547m fq575n f656n f658n fq672n f673n fq674n"
  for f in $FILTERS; do
      echo "Resampling $f"
      time sh wfc3-resample-to-muse.sh $f
  done
#+END_SRC

#+RESULTS:
#+begin_example
Resampling f469n
[struct stat="OK", time=4]
Resampling f487n
[struct stat="OK", time=3]
Resampling f502n
[struct stat="OK", time=5]
Resampling f547m
[struct stat="OK", time=4]
Resampling fq575n
[struct stat="OK", time=4]
Resampling f656n
[struct stat="OK", time=5]
Resampling f658n
[struct stat="OK", time=4]
Resampling fq672n
[struct stat="OK", time=4]
Resampling f673n
[struct stat="OK", time=5]
Resampling fq674n
[struct stat="OK", time=4]
#+end_example
*** DONE [2/2] Crop MUSE image to the WFC3 field
CLOSED: [2015-10-15 Thu 12:05]
+ [X] This is the final step required before we can do things like take ratio maps or calculate 2d histogram images
+ [X] [2015-10-15 Thu] Also, write out the integrated spectrum times filter throughput for the cropped region
#+BEGIN_SRC python :tangle crop_muse.py
  import sys
  import numpy as np
  from astropy.io import fits
  from astropy.wcs import WCS, WCSSUB_SPECTRAL
  import astropy.units as u

  def crop_muse_to_wfc3(fid):
      """Cut out a section of the MUSE image to match the WFC3 field"""
      wname = 'wfc3-resample-muse-{}.fits'.format(fid)
      mname = 'muse-hr-image-wfc3-{}.fits'.format(fid)
      whdu = fits.open(wname)[0]
      mhdu = fits.open(mname)['DATA']
      # Also get the spectral data cube multiplied by filter throughput
      shdu = fits.open(mname.replace('-image-', '-transwin-'))['DATA']
      wcs_w = WCS(whdu.header).celestial
      wcs_m = WCS(mhdu.header).celestial
      # Check that the two images have the same reference point in RA, DEC
      assert np.all(wcs_w.wcs.crval == wcs_m.wcs.crval)
      # And that the pixel scales are the same
      assert np.all(wcs_w.wcs.cdelt == wcs_m.wcs.cdelt)
      assert np.all(wcs_w.wcs.pc == wcs_m.wcs.pc)

      # The shapes of the two grids: (nx, ny) in FITS axis order
      shape_w = np.array([whdu.header['NAXIS1'], whdu.header['NAXIS2']])
      shape_m = np.array([mhdu.header['NAXIS1'], mhdu.header['NAXIS2']])

      # The difference in CRPIX values tells us the start indices (i, j)
      # for the crop window on the MUSE grid. Note that this is in
      # zero-based array indices
      start = wcs_m.wcs.crpix - wcs_w.wcs.crpix
      # The stop indices for the crop window 
      stop = start + shape_w

      # Shift 1 pixel to the right to do a coarse alignment correction
      start[0] += 1
      stop[0] += 1

      # Check that these are within bounds of the original MUSE grid
      assert np.all(start >= 0.0)
      assert np.all(stop < shape_m)

      # Crop the MUSE data array to the start:stop indices, remembering
      # that python axis order is backwards with respect to FITS axis
      # order
      mhdu.data = mhdu.data[start[1]:stop[1], start[0]:stop[0]]

      # And copy the WFC3 wcs into the new MUSE header
      mhdu.header.update(wcs_w.to_header())

      # Write out the new cropped MUSE image
      oname = mname.replace('-image-', '-cropimage-')
      mhdu.writeto(oname, clobber=True)

      # Finally, as a bonus, calculate the 1-D average spectrum from the cube
      spec = np.nanmean(shdu.data[:, start[1]:stop[1], start[0]:stop[0]], axis=(-1, -2))

      # Convert from 1e-20 flux-per-pixel to surface brightness units (flux per sr)
      pixel_area_sr = np.product(np.abs(wcs_m.wcs.cdelt))*(u.deg.to(u.radian))**2
      spec *= 1e-20/pixel_area_sr
      # extract only the spectral part of the cube's WCS
      wcs_s = WCS(shdu.header).sub([WCSSUB_SPECTRAL])
      oshdu = fits.PrimaryHDU(header=wcs_s.to_header(), data=spec)
      oshdu.header['BUNIT'] = 'erg/s/cm**2/sr/Angstrom'
      # Fix up the wavelngth units to angstrom
      oshdu.header['CDELT1'] *= 1e10
      oshdu.header['CRVAL1'] *= 1e10
      oshdu.header['CUNIT1'] = 'Angstrom'
      # And record the window from the MUSE full field that was extracted
      oshdu.header['MUSE_X1'] = start[0] + 1, 'Extracted window: start X pixel' 
      oshdu.header['MUSE_X2'] = stop[0] + 1, 'Extracted window: stop X pixel' 
      oshdu.header['MUSE_Y1'] = start[1] + 1, 'Extracted window: start Y pixel' 
      oshdu.header['MUSE_Y2'] = stop[0] + 1, 'Extracted window: stop Y pixel' 
      oshdu.writeto(mname.replace('-image-', '-cropspec1d-'), clobber=True)

      return oname


  if __name__ == '__main__':
      try:
          filter_id = sys.argv[1]
      except:
          print('Usage:', sys.argv[0], 'FILTER')

      print(crop_muse_to_wfc3(filter_id))

#+END_SRC

#+BEGIN_SRC sh :results silent
python crop_muse.py f547m
#+END_SRC

#+BEGIN_SRC sh :results verbatim
  FILTERS="f469n f487n f502n f547m fq575n f656n f658n fq672n f673n fq674n"
  for f in $FILTERS; do
      time python crop_muse.py $f
  done
#+END_SRC

#+RESULTS:
#+begin_example
muse-hr-cropimage-wfc3-f469n.fits
muse-hr-cropimage-wfc3-f487n.fits
muse-hr-cropimage-wfc3-f502n.fits
muse-hr-cropimage-wfc3-f547m.fits
muse-hr-cropimage-wfc3-fq575n.fits
muse-hr-cropimage-wfc3-f656n.fits
muse-hr-cropimage-wfc3-f658n.fits
muse-hr-cropimage-wfc3-fq672n.fits
muse-hr-cropimage-wfc3-f673n.fits
muse-hr-cropimage-wfc3-fq674n.fits
#+end_example
** Plot the cropped 1D spectra
#+BEGIN_SRC python :tangle specplot1d_utils.py
  from __future__ import print_function
  import sys
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy import units as u
  from matplotlib import pyplot as plt
  import seaborn as sns

  def plot_1d_spec_from_fits(fn, ax, fontsize=None):
      """Plots spectrum from filename `fn` onto pre-existing axis `ax`"""
      hdu = fits.open(fn)[0]
      spec = hdu.data/1e-3
      w = WCS(hdu.header)
      nwav = len(spec)
      wavs, = w.all_pix2world(range(nwav), 0)
      wavs *= u.m.to(u.Angstrom)
      #ax.plot(wavs, spec, drawstyle='steps-mid')
      ax.bar(wavs, spec, align='center', linewidth=0)
      ax.set_xlim(wavs.min(), wavs.max())
      ax.set_xlabel('Observed Air Wavelength, Angstrom', fontsize=fontsize)
      ax.set_ylabel('Filter Throughput x Brightness\n 0.001 erg/s/cm^2/sr/Angstrom', fontsize=fontsize)


  if __name__ == '__main__':
      try:
          filt = sys.argv[1]
      except IndexError:
          print('Usage:', sys.argv[0], 'FILTER')
      fig, ax = plt.subplots(1, 1)
      fn = 'muse-hr-cropspec1d-wfc3-{}.fits'.format(filt)
      plot_1d_spec_from_fits(fn, ax)
      # ax.set_yscale('log')
      # ax.set_ylim(1e-7, None)
      fig.savefig(sys.argv[0].replace('.py', '-test-{}.pdf'.format(filt)))

#+END_SRC

#+BEGIN_SRC sh
FILTERS="f469n f487n f502n f547m fq575n f656n f658n fq672n f673n fq674n"
for f in $FILTERS; do
    python specplot1d_utils.py $f
done
#+END_SRC

#+RESULTS:

** Visualizations of throughput calibration quality
The final count-rate images to be compared are 
+ Smoothed WFC3 :: wfc3-resample-muse-FILTER.fits
+ Cropped MUSE :: muse-hr-cropimage-wfc3-FILTER.fits
*** Ratios of the images
+ This will allow us to see how important misalignment is, and if there are any spatial trends

#+BEGIN_SRC python
  from astropy.io import fits

  filters_ = ["FQ575N", "FQ672N", "FQ674N", "F673N", "F469N",
              "F487N", "F656N", "F658N", "F547M", "F502N"]

  def divide_fits_images(name1, name2, outname):
      hdu1 = fits.open(name1)[0]
      hdu2 = fits.open(name2)['DATA']
      fits.PrimaryHDU(header=hdu1.header, data=hdu1.data/hdu2.data).writeto(outname, clobber=True)

  if __name__ == '__main__':
      for f in filters_:
          divide_fits_images(
              'wfc3-resample-muse-{}.fits'.format(f),
              'muse-hr-cropimage-wfc3-{}.fits'.format(f),
              'wfc3-over-muse-calib-ratio-{}.fits'.format(f)
          )
    
#+END_SRC

#+RESULTS:
: None


*** Two-d histogram of WFC3 vs MUSE-predicted count rates

#+BEGIN_SRC python :tangle histocalib.py
  from __future__ import print_function
  import numpy as np
  from astropy.io import fits
  from astropy.convolution import convolve, Gaussian2DKernel
  from matplotlib import pyplot as plt
  import seaborn as sns
  from specplot1d_utils import plot_1d_spec_from_fits

  maxcount = {
      "fq575n": 0.4,
      "fq672n": 0.6,
      "fq674n": 0.75,
      "f673n" : 2.5,
      "f469n" : 0.5,
      "f487n" : 10.0,
      "f656n" : 40.0, 
      "f658n" : 11.0, 
      "f547m" : 7.0, 
      "f502n" : 20.0,
  }
  GAMMA = 2.0

  cmap = sns.light_palette((260, 50, 30), input="husl", as_cmap=True)
  # cmap = plt.cm.gray_r

  def histogram_calib_images(f, vmax=1.0):
      name1 = 'wfc3-resample-muse-{}.fits'.format(f)
      name2 = 'muse-hr-cropimage-wfc3-{}.fits'.format(f)
      pltname = 'wfc3-vs-muse-calib-{}.pdf'.format(f)
      hdu1 = fits.open(name1)[0]
      hdu2 = fits.open(name2)['DATA']
      hduc = fits.open('wfc3-resample-muse-f547m.fits')[0]
      x, y = hdu2.data, hdu1.data
      xmin, xmax = ymin, ymax = 0.0, vmax
      ew = y/hduc.data
      # mask out silly values
      m = np.isfinite(x) & np.isfinite(y/x) & (np.abs(np.log10(y/x)) < 1.0)
      H, xedges, yedges = np.histogram2d(x[m], y[m], 200,
                                         [[xmin, xmax], [ymin, ymax]],
                                         weights=y[m])
      # Fit a straight line
      mm = m & (x > 0.05*xmax) & (y > 0.05*ymax) & (x < 0.5*xmax) & (y < 0.5*ymax) & (np.abs(np.log10(y/x)) < 0.3)
      # First, linear fit y(x) = m x + c
      y_x_linfit = np.polyfit(x[mm], y[mm], 1, w=y[mm])
      # Second, linear fit x(y) = m y + c
      x_y_linfit = np.polyfit(y[mm], x[mm], 1, w=y[mm])
      # Convert this from x(y) -> y(x)
      # If x = m y + c, then y = (1/m) x - c/m
      y_x_altfit = np.array([1./x_y_linfit[0], -x_y_linfit[1]/x_y_linfit[0]])
      # Take average and spread of these two fits
      y_x_bestfit = 0.5*(y_x_linfit + y_x_altfit)
      y_x_errfit = 0.5*np.abs(y_x_linfit - y_x_altfit)

      pbest =  np.poly1d(y_x_bestfit)

      # H = convolve(H, Gaussian2DKernel(1.0))
      fitcolor = (1.0, 0.5, 0.0)
      fitlabel = "y = ({:.2f} +/- {:.2f}) x + ({:.2f} +/- {:.2f})".format(
          y_x_bestfit[0], y_x_errfit[0], y_x_bestfit[1], y_x_errfit[1])
      fig, ax = plt.subplots(1, 1)
      ax.imshow((H.T)**(1.0/GAMMA), extent=[xmin, xmax, ymin, ymax],
                interpolation='none', aspect='auto', origin='lower', 
                cmap=cmap, alpha=1.0)
      ax.plot([0.0, x[m].max()], [0.0, x[m].max()], '-', alpha=1.0,
              lw=1, c='w', label=None)
      ax.plot([0.0, x[m].max()], pbest([0.0, x[m].max()]), '-', alpha=1.0,
              lw=1, c=fitcolor, label=fitlabel)

      leg = ax.legend(loc='upper left', title='Linear Fit', frameon=True, fancybox=True)
      leg.get_title().set_fontsize('small')
      ax.set_ylabel(
          'Observed WFC3 {} count rate, electron/s/pixel'.format(f.upper()))
      ax.set_xlabel(
          'MUSE-predicted WFC3 {} count rate, electron/s/pixel'.format(f.upper()))
      ax.set_xlim(xmin, xmax)
      ax.set_ylim(ymin, ymax)

      # Now do 1-D histogram of the deviations from the model
      ratio = y/pbest(x)
      if f == 'f547m':
          # Divide into high and low continuum counts
          s = 'counts'
          mlo = (y < y[m].mean()) & m
          mhi = (y >= y[m].mean()) & m
      else:
          # Divide into high and low EW
          s = f.upper() + '/F547M'
          mlo = (ew < np.median(ew[m])) & m
          mhi = (ew >= np.median(ew[m])) & m

      assert mlo.sum() > 0, f
      
      # inset axis at the top left
      ax2 = fig.add_axes([0.2, 0.55, 0.25, 0.25])
      ax2.hist(ratio[mlo], bins=100, range=(0.5, 1.5),
               normed=True, weights=y[mlo], alpha=0.7, label='Low '+s)
      ax2.hist(ratio[mhi], bins=100, range=(0.5, 1.5),
               normed=True, weights=y[mhi], color='red', alpha=0.3, label='High '+s)
      ax2.set_xlim(0.5, 1.5)
      # leave more space at top
      y1, y2 = ax2.get_ylim()
      y2 *= 1.2
      ax2.set_ylim(y1, y2)
      ax2.legend(loc='upper left', fontsize='xx-small')
      ax2.tick_params(labelleft=False, labelsize='x-small')
      ax2.set_xlabel('(Observed Counts) / (Linear Fit)', fontsize='xx-small')
      ax2.set_ylabel('Weighted PDF Histograms', fontsize='xx-small')
  #    ax2.set_title('PDF', fontsize='x-small')

      # inset axis at the bottom right
      ax3 = fig.add_axes([0.6, 0.2, 0.3, 0.3])
      fn = 'muse-hr-cropspec1d-wfc3-{}.fits'.format(f)
      plot_1d_spec_from_fits(fn, ax3, fontsize='xx-small')
      ax3.tick_params(labelsize='xx-small')
      ax3.set_title(f.upper())


      fig.set_size_inches(7, 7)
      fig.savefig(pltname)

      return [pltname, fitlabel]


  if __name__ == '__main__':
      for f, vmax in maxcount.items():
          print(histogram_calib_images(f, vmax))

#+END_SRC

#+RESULTS:


#+BEGIN_SRC sh
python histocalib.py 
#+END_SRC

#+RESULTS:
| ['wfc3-vs-muse-calib-f487n.pdf'  | 'y = (0.99 +/- 0.01) x + (-0.02 +/- 0.02)'] |
| ['wfc3-vs-muse-calib-f658n.pdf'  | 'y = (1.00 +/- 0.01) x + (-0.02 +/- 0.02)'] |
| ['wfc3-vs-muse-calib-f469n.pdf'  | 'y = (0.94 +/- 0.03) x + (-0.00 +/- 0.01)'] |
| ['wfc3-vs-muse-calib-fq674n.pdf' | 'y = (0.98 +/- 0.01) x + (0.01 +/- 0.00)']  |
| ['wfc3-vs-muse-calib-f656n.pdf'  | 'y = (1.02 +/- 0.01) x + (0.18 +/- 0.07)']  |
| ['wfc3-vs-muse-calib-fq672n.pdf' | 'y = (0.97 +/- 0.02) x + (0.01 +/- 0.00)']  |
| ['wfc3-vs-muse-calib-fq575n.pdf' | 'y = (1.00 +/- 0.02) x + (-0.00 +/- 0.00)'] |
| ['wfc3-vs-muse-calib-f673n.pdf'  | 'y = (0.97 +/- 0.01) x + (0.02 +/- 0.01)']  |
| ['wfc3-vs-muse-calib-f547m.pdf'  | 'y = (1.01 +/- 0.01) x + (-0.11 +/- 0.03)'] |
| ['wfc3-vs-muse-calib-f502n.pdf'  | 'y = (0.98 +/- 0.01) x + (-0.01 +/- 0.04)'] |


*** Summary of calibration results
+ Calibration constant is unity in most cases!
  + Exceptions are
    + F469N :: slope = 0.94
    + F673N :: slope = 0.97
    + F547M :: intercept = -0.11
+ Also no evidence of trend with EW


** Useful scripts
:PROPERTIES:
:header-args: :results silent
:END:
#+name: new-blank-ds9
#+BEGIN_SRC sh :results silent :var DS9="ds9"
open -n -a SAOImage\ DS9 --args -title $DS9
sleep 1
xpaset -p $DS9 view buttons no
xpaset -p $DS9 frame delete all
#+END_SRC

#+call: new-blank-ds9("cube") :results silent

#+BEGIN_SRC sh
xpaset -p cube frame new
xpaset -p cube fits $PWD/muse-hr-fullcube-rebin05x05.fits
#+END_SRC

#+BEGIN_SRC sh
xpaset -p ds9 frame new
xpaset -p ds9 fits $PWD/muse-hr-data-wavsec3.fits
#+END_SRC

#+RESULTS:


* DONE Line ratios -> T, N diagnostics for the MUSE data
CLOSED: [2015-10-26 Mon 09:18]
+ This will allow us to extend the t2 spatial scale analysis to larger scales
+ And will give us another window onto the effects of noise on the results
+ Will also be practise for redoing everything with WFC3

** De-redden the nii line ratio
#+BEGIN_SRC python :tangle muse-deredden.py
  import sys
  from astropy.io import fits

  sys.path.append('/Users/will/Work/RubinWFC3/Tsquared')
  from deredden import deredden_nii_ratio

  hb_ha = fits.open('Linemaps/ratio-4861-6563.fits')[0].data
  nii_hdu = fits.open('Linemaps/ratio-5755-6583.fits')[0]
  nii_hdu.data = deredden_nii_ratio(nii_hdu.data, hb_ha)
  nii_hdu.writeto('Linemaps/ratio-5755-6583-deredden-2874.fits', clobber=True)

  hb_ha = fits.open('NebulioMUSE/synthetic-ratio-4861-6563.fits')[0].data
  nii_hdu = fits.open('NebulioMUSE/synthetic-ratio-5755-6583.fits')[0]
  nii_hdu.data = deredden_nii_ratio(nii_hdu.data, hb_ha)
  nii_hdu.writeto('NebulioMUSE/synthetic-ratio-5755-6583-deredden-2874.fits', clobber=True)

#+END_SRC

#+BEGIN_SRC sh :results silent
python muse-deredden.py
#+END_SRC


** Plot histogram of [N II] vs [S II] line ratios
:PROPERTIES:
:ID:       012A7F6B-BC6B-433E-A5A8-E1453B1E3FCA
:END:
Based on a [[id:D15B6745-A22C-420C-A669-E39FD7954AC7][very similar program for WFC3 data]]
#+BEGIN_SRC python :tangle muse-rnii-rsii-histogram.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from matplotlib import pyplot as plt
  import pyregion
  t2dir = '/Users/will/Work/RubinWFC3/Tsquared'
  sys.path.append(t2dir)
  from pyneb_utils import rsii_T_den, rnii_T_den

  try:
      region = sys.argv[1]
  except IndexError:
      sys.exit('Usage: {} REGION [SUFFIX]'.format(sys.argv[0]))

  try:
      suffix = '-' + sys.argv[2]
  except IndexError:
      suffix = ''
  
  snii_hdu = fits.open("Linemaps/linesum-N_II-6583{}.fits".format(suffix))['SCALED']
  hduA = fits.open("Linemaps/ratio-6716-6731{}.fits".format(suffix))['SCALED']
  hduB = fits.open("Linemaps/ratio-5755-6583{}-deredden-2874.fits".format(suffix))['SCALED']
  # hduB = fits.open(prefix + "ratio-5755-6583.fits")[0]

  xmin, xmax, ymin, ymax = 0.4, 1.0, 0.0, 0.05

  m = np.isfinite(hduA.data) & np.isfinite(hduB.data)
  m = m & (hduA.data > 0.0) & (hduB.data > 0.0) 
  if 'sweet' in region.lower():
      title = 'Orion S'
      include = pyregion.open(t2dir + '/will-nii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-nii-exclude-wcs.reg')
      m = m & include.get_mask(hdu=snii_hdu) & (~exclude.get_mask(hdu=snii_hdu))

      include = pyregion.open(t2dir + '/will-sii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-sii-exclude-wcs.reg')
      m = m & include.get_mask(hdu=snii_hdu) & (~exclude.get_mask(hdu=snii_hdu))
  else:
      title = 'Full nebula'
    
  x = hduA.data[m]
  y = hduB.data[m]
  w = snii_hdu.data[m]
  gamma = 1.5
  fig, ax = plt.subplots(1, 1)
  H, xedges, yedges = np.histogram2d(x, y, 50,
                                     [[xmin, xmax], [ymin, ymax]],
                                     weights=w)
  ax.imshow((H.T)**(1.0/gamma), extent=[xmin, xmax, ymin, ymax],
            interpolation='nearest', aspect='auto', origin='lower', 
            cmap=plt.cm.gray_r, alpha=1.0)

  denrange = np.linspace(0.0, 8.e4, 200)
  for tem in [7e3, 9e3, 1.1e4, 1.3e4, 1.5e4, 1.7e4]:
      ax.plot(rsii_T_den(tem, denrange), rnii_T_den(tem, denrange),
              label="T = {:.0f} K".format(tem))

  temrange = np.linspace(5000.0, 20000.0, 100)
  for den in [1000, 2000, 4000, 8000, 16000, 32000]:
      ax.plot(rsii_T_den(temrange, den), rnii_T_den(temrange, den),
              '--', label="n = {:.0f} pcc".format(den))

  ax.set_xlim(xmin, xmax)
  ax.set_ylim(ymin, ymax)
  ax.set_xlabel('[S II] 6716 / 6731')
  ax.set_ylabel('Dereddened [N II] 5755 / 6584')
  ax.grid()
  ax.legend(ncol=2, fontsize='x-small', handlelength=2.2, numpoints=1)

  fig.set_size_inches(7, 7)
  pltfile = 'muse-rnii-rsii-histogram-{}{}.pdf'.format(region, suffix)

  fig.savefig(pltfile)
  print(pltfile)
#+END_SRC

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py sweet bin001
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-sweet-bin001.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py full bin001
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-full-bin001.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py full bin004
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-full-bin004.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py full bin016
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-full-bin016.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py full bin064
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-full-bin064.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py full bin256
#+END_SRC

#+RESULTS:
[[file:muse-rnii-rsii-histogram-full-bin256.pdf]]

#+BEGIN_SRC sh :results file
python muse-rnii-rsii-histogram.py NebulioMUSE/synthetic-
#+END_SRC

#+RESULTS:
[[file:muse-synthetic-rnii-rsii-histogram.pdf]]


** Use pyneb to calculate the Te, ne from [S II], [N II]
#+BEGIN_SRC python :tangle muse-make-te-ne-maps.py
  import sys
  import numpy as np
  from astropy.io import fits
  t2dir = '/Users/will/Work/RubinWFC3/Tsquared'
  sys.path.append(t2dir)
  from derive_ne_te_1phase import T_den_from_rsii_rnii

  prefix = 'Linemaps/'
  hduA = fits.open(prefix + "ratio-6716-6731.fits")[0]
  hduB = fits.open(prefix + "ratio-5755-6583-deredden-2874.fits")[0]

  Te = np.empty_like(hduA.data)
  Ne = np.empty_like(hduA.data)
  m = np.isfinite(hduA.data) & np.isfinite(hduB.data) & (hduA.data > 0) & (hduB.data > 0)
  Te[m], Ne[m] = T_den_from_rsii_rnii(hduA.data[m], hduB.data[m])
  Te[~m], Ne[~m] = np.nan, np.nan
  fits.PrimaryHDU(header=hduA.header, data=Te).writeto(
      prefix + 'muse-derived-Te.fits', clobber=True)
  fits.PrimaryHDU(header=hduA.header, data=Ne).writeto(
      prefix + 'muse-derived-Ne.fits', clobber=True)

#+END_SRC

#+BEGIN_SRC sh :results verbatim
time python muse-make-te-ne-maps.py
#+END_SRC

#+RESULTS:


** DONE Extension to [Cl III], [S III] pair
CLOSED: [2015-10-25 Sun 21:58]
+ We can use [Cl III] 5538/5518 for density
+ And [S III] 6312/9069 for Te
  + But it needs correcting for extinction
  + We can use the Balmer-Paschen line ratio to correct for this
  + For instance 6563/9299
  + 6563/6312 = 1.04 whereas 9299/9069 = 1.025 so not too far off
  + Dereddening is done down [[id:89D30B56-E005-4846-8CD2-FBA8C008109D][here]]
*** Plot histogram of [S III] vs [Cl III] line ratios
#+BEGIN_SRC python :tangle muse-rsiii-rcliii-histogram.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from matplotlib import pyplot as plt
  import pyregion
  t2dir = '/Users/will/Work/RubinWFC3/Tsquared'
  sys.path.append(t2dir)
  from pyneb_utils import rcliii_T_den, rsiii_T_den

  try:
      region = sys.argv[1]
  except IndexError:
      sys.exit('Usage: {} REGION [SUFFIX]'.format(sys.argv[0]))
  
  try:
      suffix = '-' + sys.argv[2]
  except IndexError:
      suffix = ''
  
  ssiii_hdu = fits.open("Linemaps/linesum-S_III-9069{}.fits".format(suffix))['SCALED']
  hduA = fits.open("Linemaps/ratio-5538-5518{}.fits".format(suffix))['SCALED']
  hduB = fits.open("Linemaps/ratio-6312-9069-deredden{}.fits".format(suffix))['SCALED']
  # hduB = fits.open(prefix + "ratio-5755-6583.fits")[0]

  xmin, xmax, ymin, ymax = 0.5, 2.5, 0.02, 0.08

  m = np.isfinite(hduA.data) & np.isfinite(hduB.data)
  if 'sweet' in region.lower():
      title = 'Orion S'
      include = pyregion.open(t2dir + '/will-nii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-nii-exclude-wcs.reg')
      m = m & include.get_mask(hdu=ssiii_hdu) & (~exclude.get_mask(hdu=ssiii_hdu))
       
      include = pyregion.open(t2dir + '/will-sii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-sii-exclude-wcs.reg')
      m = m & include.get_mask(hdu=ssiii_hdu) & (~exclude.get_mask(hdu=ssiii_hdu))
  else:
      title = 'Full nebula'

  x = hduA.data[m]
  y = hduB.data[m]
  w = ssiii_hdu.data[m]
  gamma = 1.5
  fig, ax = plt.subplots(1, 1)
  H, xedges, yedges = np.histogram2d(x, y, 50,
                                     [[xmin, xmax], [ymin, ymax]],
                                     weights=w)
  ax.imshow((H.T)**(1.0/gamma), extent=[xmin, xmax, ymin, ymax],
            interpolation='nearest', aspect='auto', origin='lower', 
            cmap=plt.cm.gray_r, alpha=1.0)

  denrange = np.linspace(0.0, 8.e4, 200)
  for tem in [7.5e3, 8e3, 8.5e3, 9e3, 9.5e3, 1e4]:
      ax.plot(rcliii_T_den(tem, denrange), rsiii_T_den(tem, denrange),
              label="T = {:.0f} K".format(tem))

  temrange = np.linspace(0.0, 20000.0, 100)
  for den in [1000, 2000, 4000, 8000, 16000, 32000]:
      ax.plot(rcliii_T_den(temrange, den), rsiii_T_den(temrange, den),
              '--', label="n = {:.0f} pcc".format(den))

  ax.set_xlim(xmin, xmax)
  ax.set_ylim(ymin, ymax)
  ax.set_xlabel('[Cl III] 5538 / 5518')
  ax.set_ylabel('Dereddened [S III] 6300 / 9069')
  ax.grid()
  ax.legend(ncol=2, fontsize='x-small', handlelength=2.2, numpoints=1)

  fig.set_size_inches(7, 7)
  pltfile = 'muse-rsiii-rcliii-histogram-{}{}.pdf'.format(region, suffix)


  fig.savefig(pltfile)
  print(pltfile)

#+END_SRC

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py sweet bin001
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-sweet-bin001.pdf]]

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py full bin001
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-full-bin001.pdf]]

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py full bin004
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-full-bin004.pdf]]

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py full bin016
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-full-bin016.pdf]]

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py full bin064
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-full-bin064.pdf]]

#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py full bin256
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-full-bin256.pdf]]



#+BEGIN_SRC sh :results file
python muse-rsiii-rcliii-histogram.py sweet bin016
#+END_SRC

#+RESULTS:
[[file:muse-rsiii-rcliii-histogram-sweet-bin016.pdf]]

** DONE Look at extinction curve in more detail
CLOSED: [2015-10-24 Sat 15:02]
+ We have the following extinction-sensitive ratios
  + Balmer decrement Hb 4861/Ha 6563
  + Balmer-Paschen decrement Ha 6563/Pa-9 9229
  + Decrements within the Pa series
    + 8545/9229
    + 8598/9229
    + 8750/9229 - contaminated with something high ionization
    + 8863/9229
    + 9015/9229 - contaminated with blueshifted something else
+ [ ] Why did we miss out 8665
+ There is broad agreement of all ratios in the main extinction features: dark bay plus sw cloud
+ But there are some interesting differences, some discussed [[id:236AC762-7034-42E9-83BC-754A68346A23][above]]
  + More relevant here is that over in the far NE, where we should be in the Dark Bay, the apparent extinction measured by the non-contaminated inter-Paschen ratios (8545/9229, 8598/9229, 8863/9229) all show /low/ extinction
  + This may be due to a foreground emission component, with low extinction
    + This makes a relatively larger contribution to the higher Pa lines
    + But why is the same effect not seen in 6563/9229?
+ Since we have 3 Pa ratios, we can fit pixel-by-pixel for:
  1. Magnitud of extinction
  2. Slope of extinction
  3. Foreground contamination
+ But we would probably best off making (3) fixed at least, and maybe (2) too
*** Pyneb calculations of the intrinsic Balmer and Paschen decrements
+ Based on Balmer decrement calculation I did [[id:6FCC69BB-E453-4B3F-A9F6-DC6A1203542F][here]]
+ So none of these vary much unless T < 4000 K
+ Previously we had taken 1/2.874 = 0.3479 for Hb/Ha, which applies for T = 1e4 K over a large range of n
+ It looks like we should use an 6563/9229 intrinsic ratio of 113.0
#+BEGIN_SRC python :tangle intrinsic-H-line-ratios.py
  import numpy as np
  from matplotlib import pyplot as plt
  import pyneb
  h1 = pyneb.RecAtom('H', 1)
  tems = [2000, 4000, 8000, 12000, 16000, 20000]
  den = np.logspace(2.0, 6.0)
  linepairs = [
      [(2, 4), (2, 3)],
      [(2, 3), (3, 9)],
      [(3, 10), (3, 9)],
      [(3, 11), (3, 9)],
      [(3, 12), (3, 9)],
      [(3, 13), (3, 9)],
      [(3, 14), (3, 9)],
      [(3, 15), (3, 9)],
      [(3, 16), (3, 9)],
      [(3, 17), (3, 9)],
  ]
  for levelsA, levelsB in linepairs:
      wavA = h1.getWave(*levelsA)
      wavB = h1.getWave(*levelsB)
      fig, ax = plt.subplots(1, 1)
      for T in tems:
          # Level order is backward for emissivity
          emA = h1.getEmissivity(T, den, *levelsA[::-1])
          emB = h1.getEmissivity(T, den, *levelsB[::-1])
          ax.plot(den, emA/emB, label='T = {:.0f} K'.format(T))
      ax.set_xscale('log')
      ax.set_xlim(den.min(), den.max())
      ax.set_ylim(0.0, None)
      ax.set_xlabel('Density, pcc')
      ax.set_ylabel('Line Ratio H({}-{})/H({}-{})'.format(*(levelsA[::-1]+levelsB[::-1])))
      ax.set_title('H I {:.2f} / {:.2f}'.format(wavA, wavB))
      ax.legend(loc='lower right', fontsize='small')
      fig.set_size_inches(7, 7)
      fig.savefig('intrinsic-ratio-H_I_{}_{}.pdf'.format(int(wavA+0.5), int(wavB+0.5)))
#+END_SRC

#+BEGIN_SRC sh :results silent
python intrinsic-H-line-ratios.py && open intrinsic-ratio-H_I_*.pdf
#+END_SRC
** DONE De-redden the [S III] ratio
CLOSED: [2015-10-25 Sun 11:42]
:PROPERTIES:
:ID:       89D30B56-E005-4846-8CD2-FBA8C008109D
:END:
+ E(lam1-lam2) = E(lam1-Hb) - E(lam2-Hb)
+ E(lam-Hb) = f(lam) A(Hb)
+ => E(lam1-lam2) = (f(lam1) - f(lam2)) A(Hb)
+ observed ratio r12 = r0 10^[-0.4 E(lam1-lam2)]
  + e.g r(6312/9069) = r0(6312/9069) 10^[-0.4 E(6312-9069)]
  + E(6312-9069) = -2.5 log(r(6312/9069) / r0(6312/9069))
  + We want to find r0(6312/9069)
+ Same for reddening diagnostic lines:
  + E(lamA-lamB) = (f(lamA) - f(lamB)) A(Hb)
  + => E(lam1-lam2) = E(lamA-lamB) (f(lam1) - f(lam2)) / (f(lamA) - f(lamB))
  + or E(lam1-lam2) = F E(lamA-lamB) where f is that ratio of f differences
  + And also E(lamA-lamB) = -2.5 log(rAB/rAB0)
+ Therefore -2.5 log(r(6312/9069) / r0(6312/9069)) = -2.5 F log(rAB/rAB0)
  + => r(6312/9069) / r0(6312/9069) = (rAB/rAB0)^F
  + => r0(6312/9069) = r(6312/9069) (rAB0/rAB)^F

#+BEGIN_SRC python :tangle deredden_siii.py
  import sys
  import numpy as np
  from astropy.io import fits

  # Blagrave extinction law interpolated on table
  # -0.138 + (6312 - 5876)*(-0.218 - (-0.138))/(6548 - 5876)
  f_6312 = -0.1899
  # -0.309 + (9069 - 7330)*(-0.507 - (-0.309))/(9229 - 7330)
  f_9069 = -0.4903
  f_6563 = -0.220
  f_9229 = -0.507

  F_siii_ha_pa9 = (f_6312 - f_9069) / (f_6563 - f_9229) # Should be 1.0467

  def deredden_siii_ratio(rsiii, rha_pa9, ha_pa9_intrinsic=113.0):
      """Uses the Blagrave reddening law"""
      return rsiii*(ha_pa9_intrinsic/rha_pa9)**F_siii_ha_pa9

  if __name__ == '__main__':
      try:
          suffix = '-' + sys.argv[1]
      except IndexError:
          suffix = ''
        
      rha_pa9 = fits.open('Linemaps/ratio-6563-9229{}.fits'.format(suffix))['SCALED'].data
      siii_hdu = fits.open('Linemaps/ratio-6312-9069{}.fits'.format(suffix))['SCALED']
      siii_hdu.data = deredden_siii_ratio(siii_hdu.data, rha_pa9)
      siii_hdu.writeto('Linemaps/ratio-6312-9069-deredden{}.fits'.format(suffix),
                      clobber=True)
#+END_SRC

#+BEGIN_SRC sh :results verbatim
  for binning in 001 002 004 008 016 032 064 128 256; do
      python deredden_siii.py bin$binning
  done
#+END_SRC

#+RESULTS:

* TODO Multi-resolution MUSE line maps
+ This is stolen from a [[id:EAE1FA1C-7D1B-484D-9B4A-FF42DE7D8594][similar program for the Alba project]]
+ The difference is that we are starting from a simple image, not from a superposition of slits
+ Extra inspiration (e.g., star mask) is taken from [[id:B8D31952-3114-4FE8-B2D7-A0CC32287FA2][here]]
#+BEGIN_SRC python :tangle multibin-map.py
from __future__ import print_function
import sys
import numpy as np
sys.path.append('/Users/will/Work/RubinWFC3/Tsquared')
from rebin_utils import downsample, oversample
from astropy.io import fits

nlist = [1, 2, 4, 8, 16, 32, 64, 128, 256]
mingoods = [2, 2, 2, 2, 2, 2, 2, 2, 2]

try: 
    infile = sys.argv[1]
except:
    sys.exit('Usage: {} FITSFILE'.format(sys.argv[0]))


hdu = fits.open(infile)[0]
hdr = hdu.header
im = hdu.data
w = np.ones_like(hdu.data)

continuum = fits.open('muse-hr-image-wfc3-f547m.fits')['DATA'].data
starmask = continuum > 30
m =  np.isfinite(hdu.data) & (hdu.data > 0.0) & (~starmask)
for n, mingood in zip(nlist, mingoods):
    im[~m] = 0.0
    outfile = infile.replace('.fits', '-bin{:03d}.fits'.format(n))
    print('Saving', outfile)
    # Save both the scaled image and the weights, but at the full resolution
    fits.HDUList([
        fits.PrimaryHDU(),
        fits.ImageHDU(data=oversample(im, n), header=hdr, name='scaled'),
        fits.ImageHDU(data=oversample(w, n), header=hdr, name='weight'),
    ]).writeto(outfile, clobber=True)
    # Now do the rebinning by a factor of two
    [im,], m, w = downsample([im,], m, weights=w, mingood=mingood)


#+END_SRC

#+BEGIN_SRC sh :results verbatim
python multibin-map.py LineMaps/linesum-Cl_III-5538.fits
#+END_SRC

#+RESULTS:
: Saving LineMaps/linesum-Cl_III-5538-bin001.fits
: Saving LineMaps/linesum-Cl_III-5538-bin002.fits
: Saving LineMaps/linesum-Cl_III-5538-bin004.fits
: Saving LineMaps/linesum-Cl_III-5538-bin008.fits
: Saving LineMaps/linesum-Cl_III-5538-bin016.fits
: Saving LineMaps/linesum-Cl_III-5538-bin032.fits
: Saving LineMaps/linesum-Cl_III-5538-bin064.fits
: Saving LineMaps/linesum-Cl_III-5538-bin128.fits
: Saving LineMaps/linesum-Cl_III-5538-bin256.fits


Do them all
#+BEGIN_SRC sh :results verbatim
linelist=LineMaps/linesum-*[0-9][0-9][0-9][0-9].fits
for line in $linelist; do
    echo "Processing $line"
    time python multibin-map.py $line > ${line}-multibin.log
done
#+END_SRC

#+RESULTS:
#+begin_example
Processing LineMaps/linesum-Ar_III-5192.fits
Processing LineMaps/linesum-Ar_III-7136.fits
Processing LineMaps/linesum-Ar_III-7751.fits
Processing LineMaps/linesum-C_I-8727.fits
Processing LineMaps/linesum-C_II-5890.fits
Processing LineMaps/linesum-C_II-6578.fits
Processing LineMaps/linesum-Ca_I-9052.fits
Processing LineMaps/linesum-Ca_I-9095.fits
Processing LineMaps/linesum-Cl_II-8579.fits
Processing LineMaps/linesum-Cl_III-5518.fits
Processing LineMaps/linesum-Cl_III-5538.fits
Processing LineMaps/linesum-Cl_IV-8046.fits
Processing LineMaps/linesum-Fe_II-5262.fits
Processing LineMaps/linesum-Fe_II-6133.fits
Processing LineMaps/linesum-Fe_II-7453.fits
Processing LineMaps/linesum-Fe_II-8617.fits
Processing LineMaps/linesum-Fe_III-4658.fits
Processing LineMaps/linesum-Fe_III-4702.fits
Processing LineMaps/linesum-Fe_III-5270.fits
Processing LineMaps/linesum-H_I-4861.fits
Processing LineMaps/linesum-H_I-6563.fits
Processing LineMaps/linesum-H_I-8438.fits
Processing LineMaps/linesum-H_I-8467.fits
Processing LineMaps/linesum-H_I-8502.fits
Processing LineMaps/linesum-H_I-8545.fits
Processing LineMaps/linesum-H_I-8598.fits
Processing LineMaps/linesum-H_I-8665.fits
Processing LineMaps/linesum-H_I-8750.fits
Processing LineMaps/linesum-H_I-8863.fits
Processing LineMaps/linesum-H_I-9015.fits
Processing LineMaps/linesum-H_I-9229.fits
Processing LineMaps/linesum-He_I-5016.fits
Processing LineMaps/linesum-He_I-5048.fits
Processing LineMaps/linesum-He_I-5876.fits
Processing LineMaps/linesum-He_I-6678.fits
Processing LineMaps/linesum-He_I-7065.fits
Processing LineMaps/linesum-N_I-5199.fits
Processing LineMaps/linesum-N_I-8680.fits
Processing LineMaps/linesum-N_II-5755.fits
Processing LineMaps/linesum-N_II-5932.fits
Processing LineMaps/linesum-N_II-5942.fits
Processing LineMaps/linesum-N_II-5952.fits
Processing LineMaps/linesum-N_II-6548.fits
Processing LineMaps/linesum-N_II-6583.fits
Processing LineMaps/linesum-O_I-5577.fits
Processing LineMaps/linesum-O_I-6046.fits
Processing LineMaps/linesum-O_I-6300.fits
Processing LineMaps/linesum-O_I-6364.fits
Processing LineMaps/linesum-O_I-7002.fits
Processing LineMaps/linesum-O_I-8446.fits
Processing LineMaps/linesum-O_II-4650.fits
Processing LineMaps/linesum-O_II-7318.fits
Processing LineMaps/linesum-O_II-7330.fits
Processing LineMaps/linesum-O_III-4959.fits
Processing LineMaps/linesum-O_III-5007.fits
Processing LineMaps/linesum-S_II-6716.fits
Processing LineMaps/linesum-S_II-6731.fits
Processing LineMaps/linesum-S_III-6312.fits
Processing LineMaps/linesum-S_III-9069.fits
Processing LineMaps/linesum-Si_II-5041.fits
Processing LineMaps/linesum-Si_II-5056.fits
Processing LineMaps/linesum-Si_II-5958.fits
Processing LineMaps/linesum-Si_II-5979.fits
Processing LineMaps/linesum-Si_II-6347.fits
Processing LineMaps/linesum-Si_II-6371.fits
#+end_example


** Ratio of multibin maps
:PROPERTIES:
:ID:       125BB238-D032-4FAD-B6DA-FBFB14DAD3AF
:END:
#+name: ratio-pairs
+ N_II-5755;N_II-6583
+ S_III-6312;S_III-9069
+ Cl_III-5538;Cl_III-5518
+ S_II-6716;S_II-6731
+ H_I-6563;H_I-4861
+ H_I-4861;H_I-6563
+ H_I-6563;H_I-9229
+ H_I-8545;H_I-9229
+ H_I-8598;H_I-9229
+ H_I-8750;H_I-9229
+ H_I-8863;H_I-9229
+ H_I-9015;H_I-9229
+ O_II-7318;O_II-7330
+ He_I-5876;He_I-6678
+ Ar_III-7136;Ar_III-7751
+ O_I-7002;O_I-8446
+ Fe_III-4658;H_I-4861

What a palaver it is to deal with array variables in bash
#+name: ratio-multibin
#+BEGIN_SRC sh :var list=ratio-pairs :results verbatim
for pair in $list; do
    arr_pair=(${pair//;/ })
    echo ${arr_pair[0]} ${arr_pair[1]} 
    for binning in 001 002 004 008 016 032 064 128 256; do
        python muse_line_ratio.py ${arr_pair[0]} ${arr_pair[1]} linesum bin$binning > /dev/null
    done
done
#+END_SRC

#+RESULTS: ratio-multibin
#+begin_example
N_II-5755 N_II-6583
S_III-6312 S_III-9069
Cl_III-5538 Cl_III-5518
S_II-6716 S_II-6731
H_I-6563 H_I-4861
H_I-4861 H_I-6563
H_I-6563 H_I-9229
H_I-8545 H_I-9229
H_I-8598 H_I-9229
H_I-8750 H_I-9229
H_I-8863 H_I-9229
H_I-9015 H_I-9229
O_II-7318 O_II-7330
He_I-5876 He_I-6678
Ar_III-7136 Ar_III-7751
O_I-7002 O_I-8446
Fe_III-4658 H_I-4861
#+end_example

#+name: more-ratio-pairs
+ O_I-6300;O_I-8446
+ O_I-6300;O_II-7318
+ O_III-5007;O_II-7318
+ O_I-8446;O_II-7318
+ O_I-8446;H_I-8545
+ Ar_III-5192;Ar_III-7136 
+ Ar_III-7751;Ar_III-7136
+ Fe_III-4702;Fe_III-4658 
+ Fe_III-5270;Fe_III-4658 
+ O_III-5007;O_III-4959
+ N_II-6583;N_II-6548

#+call: ratio-multibin[:results output verbatim](list=more-ratio-pairs)

#+RESULTS:
: O_I-6300 O_I-8446
: O_I-6300 O_II-7318
: O_III-5007 O_II-7318
: O_I-8446 O_II-7318

#+name: yet-more-ratio-pairs
+ O_I-6364;O_I-6300
+ N_I-5199;O_I-8446
+ N_I-5199;O_I-7002
#+call: ratio-multibin[:results output verbatim](list=yet-more-ratio-pairs)

#+RESULTS:
: O_I-6364 O_I-6300
: N_I-5199 O_I-8446
: N_I-5199 O_I-7002



#+BEGIN_SRC sh :results verbatim
for binning in 001 002 004 008 016 032 064 128 256; do
    python muse_line_ratio.py N_II-5755 N_II-6583 linesum bin$binning 
done
#+END_SRC

#+RESULTS:
: LineMaps/linesum-N_II-5755-bin001.fits LineMaps/linesum-N_II-6583-bin001.fits
: LineMaps/linesum-N_II-5755-bin002.fits LineMaps/linesum-N_II-6583-bin002.fits
: LineMaps/linesum-N_II-5755-bin004.fits LineMaps/linesum-N_II-6583-bin004.fits
: LineMaps/linesum-N_II-5755-bin008.fits LineMaps/linesum-N_II-6583-bin008.fits
: LineMaps/linesum-N_II-5755-bin016.fits LineMaps/linesum-N_II-6583-bin016.fits
: LineMaps/linesum-N_II-5755-bin032.fits LineMaps/linesum-N_II-6583-bin032.fits
: LineMaps/linesum-N_II-5755-bin064.fits LineMaps/linesum-N_II-6583-bin064.fits
: LineMaps/linesum-N_II-5755-bin128.fits LineMaps/linesum-N_II-6583-bin128.fits
: LineMaps/linesum-N_II-5755-bin256.fits LineMaps/linesum-N_II-6583-bin256.fits


** Te, Ne from multibin maps
#+BEGIN_SRC python :tangle muse-make-te-ne-maps-rebin.py
  import sys
  import numpy as np
  from astropy.io import fits
  t2dir = '/Users/will/Work/RubinWFC3/Tsquared'
  sys.path.append(t2dir)
  from derive_ne_te_1phase import T_den_from_rsii_rnii
  from deredden import deredden_nii_ratio

  prefix = 'Linemaps/'
  nlist = [1, 2, 4, 8, 16, 32, 64, 128, 256]

  for n in nlist:
      suffix = '-bin{:03d}'.format(n)

      hduA = fits.open(prefix + "ratio-6716-6731{}.fits".format(suffix))[1]
      hduB = fits.open(prefix + "ratio-5755-6583{}.fits".format(suffix))[1]
      hb_ha = fits.open(prefix + "ratio-4861-6563{}.fits".format(suffix))[1].data
      hduB.data = deredden_nii_ratio(hduB.data, hb_ha)
      hduB.writeto('Linemaps/ratio-5755-6583{}-deredden-2874.fits'.format(suffix),
                   clobber=True)

      Te = np.empty_like(hduA.data)
      Ne = np.empty_like(hduA.data)
      m = (np.isfinite(hduA.data) & np.isfinite(hduB.data)
           & (hduA.data > 0) & (hduB.data > 0))
      Te[m], Ne[m] = T_den_from_rsii_rnii(hduA.data[m], hduB.data[m])
      Te[~m], Ne[~m] = np.nan, np.nan
      fits.PrimaryHDU(header=hduA.header, data=Te).writeto(
          prefix + 'muse-derived-Te{}.fits'.format(suffix), clobber=True)
      fits.PrimaryHDU(header=hduA.header, data=Ne).writeto(
          prefix + 'muse-derived-Ne{}.fits'.format(suffix), clobber=True)

#+END_SRC

#+BEGIN_SRC sh :results verbatim
time python muse-make-te-ne-maps-rebin.py
#+END_SRC

And the same for [Cl III] and [S III]
#+BEGIN_SRC python :tangle muse-make-te-ne-maps-iii-rebin.py
  import sys
  import numpy as np
  from astropy.io import fits
  t2dir = '/Users/will/Work/RubinWFC3/Tsquared'
  sys.path.append(t2dir)
  from derive_ne_te_1phase import T_den_from_rcliii_rsiii

  prefix = 'Linemaps/'
  nlist = [1, 2, 4, 8, 16, 32, 64, 128, 256]

  for n in nlist:
      suffix = '-bin{:03d}'.format(n)

      hduA = fits.open(prefix + "ratio-5538-5518{}.fits".format(suffix))[1]
      hduB = fits.open(prefix + "ratio-6312-9069-deredden{}.fits".format(suffix))[1]

      Te = np.empty_like(hduA.data)
      Ne = np.empty_like(hduA.data)
      m = (np.isfinite(hduA.data) & np.isfinite(hduB.data)
           & (hduA.data > 0) & (hduB.data > 0))
      Te[m], Ne[m] = T_den_from_rcliii_rsiii(hduA.data[m], hduB.data[m])
      Te[~m], Ne[~m] = np.nan, np.nan
      fits.PrimaryHDU(header=hduA.header, data=Te).writeto(
          prefix + 'muse-derived-Te-iii{}.fits'.format(suffix), clobber=True)
      fits.PrimaryHDU(header=hduA.header, data=Ne).writeto(
          prefix + 'muse-derived-Ne-iii{}.fits'.format(suffix), clobber=True)

#+END_SRC

#+BEGIN_SRC sh :results verbatim
time python muse-make-te-ne-maps-iii-rebin.py
#+END_SRC

#+RESULTS:


** Te - Ne distribution histograms
+ We want to get to the stuff in the ipynb file
+ Similar to other [[id:012A7F6B-BC6B-433E-A5A8-E1453B1E3FCA][histogram plot programs]]
+ But this does several different correlations
  + Te([N II]) vs Ne([S II])
  + Te([N II]) vs Te([S III])
  + Ne([S II]) vs Ne([Cl III])
  + Te([S III]) vs Ne([Cl III])


#+BEGIN_SRC python :tangle muse-Te-Ne-histograms.py
  from __future__ import print_function
  import sys
  import numpy as np
  from astropy.io import fits
  from matplotlib import pyplot as plt
  import pyregion
  t2dir = '/Users/will/Work/RubinWFC3/Tsquared'
  sys.path.append(t2dir)
  from pyneb_utils import rsii_T_den, rnii_T_den
  from misc_utils import sanitize_string


  try:
      region = sys.argv[1]
      suffix = sys.argv[2]
  except IndexError:
      sys.exit('Usage: {} REGION [SUFFIX]'.format(sys.argv[0]))

  file_patterns = {
      'T([N II])'  : 'muse-derived-Te-bin{}.fits',
      'N([S II])'  : 'muse-derived-Ne-bin{}.fits',
      'T([S III])' : 'muse-derived-Te-iii-bin{}.fits',
      'N([Cl III])': 'muse-derived-Ne-iii-bin{}.fits',
      'S(Pa 9)'    : 'linesum-H_I-9229-bin{}.fits',
      'S(5755)'    : 'linesum-N_II-5755-bin{}.fits',
      'S(6716)'    : 'linesum-S_II-6716-bin{}.fits',
      'S(6312)'    : 'linesum-S_III-6312-bin{}.fits',
      'S(5518)'    : 'linesum-Cl_III-5518-bin{}.fits',
  }

  minmax = {
      'T([N II])'  : [5000.0, 15000.],
      'N([S II])'  : [100.0, 1e5],
      'T([S III])' : [5000.0, 15000.], 
      'N([Cl III])': [100.0, 1e5],
      'S(Pa 9)'    : [0.01, 8.0],
      'S(5755)'    : [0.01, 8.0],
      'S(6716)'    : [0.01, 8.0],
      'S(6312)'    : [0.01, 8.0],
      'S(5518)'    : [0.01, 8.0],
  }



  hdus = {k: fits.open('Linemaps/' + v.format(suffix))['SCALED']
          for k, v in file_patterns.items()}

  # Rescale brightnesses to give nicer numbers
  for k in hdus:
      if k.startswith('S'):
          hdus[k].data /= 1.e5

  pairs = [
      ['T([N II])', 'T([S III])'],
      ['N([S II])', 'N([Cl III])'],
      ['N([S II])', 'T([N II])'],
      ['N([Cl III])', 'T([S III])'],
      # ['S(Pa 9)', 'N([S II])'],
      # ['S(Pa 9)', 'N([Cl III])'],
      # ['S(Pa 9)', 'T([N II])'],
      # ['S(Pa 9)', 'T([S III])'],
      ['S(6716)', 'N([S II])'],
      ['S(5518)', 'N([Cl III])'],
      ['S(5755)', 'T([N II])'],
      ['S(6312)', 'T([S III])'],
  ]

  # Pairs that need to know about each other because of co-dependent ratios
  complements = {
      'N([S II])': 'T([N II])', 
      'T([N II])': 'N([S II])', 
      'N([Cl III])': 'T([S III])', 
      'T([S III])': 'N([Cl III])', 
  }

  weighting_maps = {
      'N([S II])': 'S(6716)', 
      'T([N II])': 'S(5755)', 
      'N([Cl III])': 'S(5518)', 
      'T([S III])': 'S(6312)', 
  }

  mm = np.isfinite(hdus['S(Pa 9)'].data) & (hdus['S(Pa 9)'].data > 0.0) 
  if 'sweet' in region.lower():
      title = 'Orion S'
      include = pyregion.open(t2dir + '/will-nii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-nii-exclude-wcs.reg')
      mm = mm & include.get_mask(hdu=hdus['S(Pa 9)']) & (~exclude.get_mask(hdu=hdus['S(Pa 9)']))

      include = pyregion.open(t2dir + '/will-sii-sweet-spot-wcs.reg')
      exclude = pyregion.open(t2dir + '/will-sii-exclude-wcs.reg')
      mm = mm & include.get_mask(hdu=hdus['S(Pa 9)']) & (~exclude.get_mask(hdu=hdus['S(Pa 9)']))
  else:
      title = 'Full nebula'


  for xlabel, ylabel in pairs:
      hduA = hdus[xlabel]
      hduB = hdus[ylabel]
      xmin, xmax = minmax[xlabel]
      ymin, ymax = minmax[ylabel]

      m = mm & np.isfinite(hduA.data) & np.isfinite(hduB.data)
      m = m & (hduA.data > xmin) & (hduB.data > ymin) 
      m = m & (hduA.data < xmax) & (hduB.data < ymax) 

      wlabels = []
      for label in xlabel, ylabel:
          # Make a list of quantities to use as weights for this map
          if label in weighting_maps:
              wlabels.append(weighting_maps[label])
          else:
              wlabels.append(label)
          # Also check complementary vars for being out-of-range
          if label in complements:
              zlabel = complements[label]
              zmin, zmax = minmax[zlabel]
              hduC = hdus[zlabel]
              m = m & (hduC.data > zmin) & (hduC.data < zmax)

      x = hduA.data[m]
      y = hduB.data[m]
      w = np.zeros_like(x)
      for wlabel in set(wlabels):
          w += hdus[wlabel].data[m]
      gamma = 1.5
      fig, ax = plt.subplots(1, 1)
      # Use a log scale for surface brightnesses and densities
      if xlabel.startswith('S') or xlabel.startswith('N'):
          x = np.log10(x)
          xmin, xmax = np.log10(xmin), np.log10(xmax)
          xlabel = 'log10[ {} ]'.format(xlabel)
      if ylabel.startswith('S') or ylabel.startswith('N'):
          y = np.log10(y)
          ymin, ymax = np.log10(ymin), np.log10(ymax)
          ylabel = 'log10[ {} ]'.format(ylabel)
      H, xedges, yedges = np.histogram2d(x, y, 50,
                                         [[xmin, xmax], [ymin, ymax]],
                                         weights=w)
      ax.imshow((H.T)**(1.0/gamma), extent=[xmin, xmax, ymin, ymax],
                interpolation='nearest', aspect='auto', origin='lower', 
                cmap=plt.cm.gray_r, alpha=1.0)

      ax.set_xlim(xmin, xmax)
      ax.set_ylim(ymin, ymax)
      ax.set_xlabel(xlabel)
      ax.set_ylabel(ylabel)
      ax.grid()

      fig.set_size_inches(4, 4)
      fig.tight_layout()
      pltfile = 'muse-{}-{}-histogram-{}{}.pdf'.format(sanitize_string(xlabel),
                                                       sanitize_string(ylabel),
                                                       region, suffix)

      fig.savefig(pltfile)
      print(pltfile)

#+END_SRC


#+BEGIN_SRC sh :results verbatim
source activate py27
for bin in 001 004 016 064; do
    python muse-Te-Ne-histograms.py full $bin
done
#+END_SRC

#+RESULTS:
#+begin_example
muse-T_N_II-T_S_III-histogram-full001.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-full001.pdf
muse-log10_N_S_II_-T_N_II-histogram-full001.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-full001.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-full001.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-full001.pdf
muse-log10_S_5755_-T_N_II-histogram-full001.pdf
muse-log10_S_6312_-T_S_III-histogram-full001.pdf
muse-T_N_II-T_S_III-histogram-full004.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-full004.pdf
muse-log10_N_S_II_-T_N_II-histogram-full004.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-full004.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-full004.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-full004.pdf
muse-log10_S_5755_-T_N_II-histogram-full004.pdf
muse-log10_S_6312_-T_S_III-histogram-full004.pdf
muse-T_N_II-T_S_III-histogram-full016.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-full016.pdf
muse-log10_N_S_II_-T_N_II-histogram-full016.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-full016.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-full016.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-full016.pdf
muse-log10_S_5755_-T_N_II-histogram-full016.pdf
muse-log10_S_6312_-T_S_III-histogram-full016.pdf
muse-T_N_II-T_S_III-histogram-full064.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-full064.pdf
muse-log10_N_S_II_-T_N_II-histogram-full064.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-full064.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-full064.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-full064.pdf
muse-log10_S_5755_-T_N_II-histogram-full064.pdf
muse-log10_S_6312_-T_S_III-histogram-full064.pdf
#+end_example



#+RESULTS:
#+BEGIN_SRC sh
open muse-log10_S_5518_-log10_N_Cl_III_-histogram-full???.pdf
open muse-log10_S_6312_-T_S_III-histogram-full???.pdf
open muse-log10_S_6716_-log10_N_S_II_-histogram-full???.pdf
open muse-log10_S_5755_-T_N_II-histogram-full???.pdf
#+END_SRC

#+BEGIN_SRC sh
open muse-log10_N_S_II_-log10_N_Cl_III_-histogram-full???.pdf
open muse-T_N_II-T_S_III-histogram-full???.pdf
open muse-log10_N_S_II_-T_N_II-histogram-full???.pdf
open muse-log10_N_Cl_III_-T_S_III-histogram-full???.pdf
#+END_SRC

#+RESULTS:

#+RESULTS:

#+BEGIN_SRC sh :results verbatim
source activate py27
for bin in 001 004 016 064; do
    python muse-Te-Ne-histograms.py sweet $bin
done
#+END_SRC

#+RESULTS:
#+begin_example
muse-T_N_II-T_S_III-histogram-sweet001.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-sweet001.pdf
muse-log10_N_S_II_-T_N_II-histogram-sweet001.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-sweet001.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-sweet001.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-sweet001.pdf
muse-log10_S_5755_-T_N_II-histogram-sweet001.pdf
muse-log10_S_6312_-T_S_III-histogram-sweet001.pdf
muse-T_N_II-T_S_III-histogram-sweet004.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-sweet004.pdf
muse-log10_N_S_II_-T_N_II-histogram-sweet004.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-sweet004.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-sweet004.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-sweet004.pdf
muse-log10_S_5755_-T_N_II-histogram-sweet004.pdf
muse-log10_S_6312_-T_S_III-histogram-sweet004.pdf
muse-T_N_II-T_S_III-histogram-sweet016.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-sweet016.pdf
muse-log10_N_S_II_-T_N_II-histogram-sweet016.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-sweet016.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-sweet016.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-sweet016.pdf
muse-log10_S_5755_-T_N_II-histogram-sweet016.pdf
muse-log10_S_6312_-T_S_III-histogram-sweet016.pdf
muse-T_N_II-T_S_III-histogram-sweet064.pdf
muse-log10_N_S_II_-log10_N_Cl_III_-histogram-sweet064.pdf
muse-log10_N_S_II_-T_N_II-histogram-sweet064.pdf
muse-log10_N_Cl_III_-T_S_III-histogram-sweet064.pdf
muse-log10_S_6716_-log10_N_S_II_-histogram-sweet064.pdf
muse-log10_S_5518_-log10_N_Cl_III_-histogram-sweet064.pdf
muse-log10_S_5755_-T_N_II-histogram-sweet064.pdf
muse-log10_S_6312_-T_S_III-histogram-sweet064.pdf
#+end_example


#+BEGIN_SRC sh
open muse-log10_S_5518_-log10_N_Cl_III_-histogram-sweet???.pdf
open muse-log10_S_6312_-T_S_III-histogram-sweet???.pdf
open muse-log10_S_6716_-log10_N_S_II_-histogram-sweet???.pdf
open muse-log10_S_5755_-T_N_II-histogram-sweet???.pdf
#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh
open muse-S_Pa_9-T_S_III-histogram-sweet???.pdf
#+END_SRC

#+RESULTS:

* Correlations between Te, Ne and other things

** Crazy things we could calculate

*** TODO Mean ionizing flux distribution
+ From the [O III]/[O II] ratio and assuming Ne([Cl III]) and Te([S III]) we can estimate what the flux in the O+ ionizing continuum is
+ This comes from the following:
  + O ionization balance: F \sigma n(O+) = \alpha n(e) n(O++)
  + [O III] Surface brightness: S([O III]) = \int n(e) n(O++) fIII(T) dz
  + [O II] Surface brightness: S([O II]) = \int n(e) n(O+) fII(T) dz
+ => "average" n(O++)/n(O+) = {S([O III]) / S([O II])} {fII(T) / fIII(T)}
+ => "average" F = (\alpha/\sigma) n(e) (fII/fIII) R(5007/7318)
+ But we have to correct 5007/7318 for extinction first
  + We should probably correct all the lines for extinction



* Thoughts on large scale features of the nebula

** The neutral filaments
+ These are best revealed in the O I 8446 / H I 8545 ratio
  + That is the closest Paschen line to the strongest O I permitted line that is not contaminated with something
+ The filaments show all the classic bars
  + Bright Bar
  + Trapezium Compact Bar
  + SW Compact Bar
+ What we called the Near E Bar in GDH07 turns out to be part of a knotty C-shaped shell that runs from N of Trap (intermediate between Trap Compact Bar and E-W Bright Bar) round to E, then turns S to form the Near E Bright Bar and then when it gets to SE of Trap it curves to the W again to run parallel to the Big Arc
  + It looks like it could possibly be related with the Big Arc
    + But in [O I] it does not have high velocity: +10 km/s at bluest, which is bluer than the Bright Bar (which is more like +20), but nothing like as blue as the Big Arc
    + So it is probably unrelated
  + So is it on the near side or the far side?
* Exploring the data cubes
** Original data locations
At CRyA in =/fs/nil/other0/will/orion-muse/DATA= 
+ LR :: 1.25 Angstrom sampling: DATACUBEFINALuser_20140216T010259_cf767044.fits
+ HR :: 0.85 Angstrom sampling: DATACUBEFINALuser_20140216T010259_78380e1d.fits
*** LR cube
+ Dimensions:
  + NV = 3818
  + NY = 1476
  + NX = 1766
+ Scales:
  + Spatial: 0.2 arcsec
  + Wavelength: 1.25 Ang
**** Reading in the cube
#+BEGIN_SRC python
from astropy.io import fits
from astropy import wcs
import numpy as np
hdulist = fits.open('DATA/DATACUBEFINALuser_20140216T010259_cf767044.fits')
cube = hdulist['DATA']
#+END_SRC
Note that this does not read the full data cube (40 GB) into memory unless we need to do something with it.
**** Extracting the Orion S region
+ To start with, we will look at a 300x300 box centered on (1050, 550)
+ This is more or less the quad filter region
#+BEGIN_SRC python
  subcube = cube.data[:, 400:700, 900:1200]
  spec = np.nansum(np.nansum(subcube, axis=-1), axis=-1)
  spechdu = fits.PrimaryHDU(header=cube.header, data=spec.reshape((3818, 1, 1)))
  spechdu.writeto('subcube-spec.fits')
#+END_SRC
+ So this gives the summed spectrum of the region
+ Note that I did a reshape on the array so that wavelength is still the 3rd FITS axis.  So that the header WCS keywords don't need changing 
#+BEGIN_SRC sh
rsync -avzP nil:/fs/nil/other0/will/orion-muse/subcube-spec.fits .
#+END_SRC
+ The spectrum shows up as a single pixel in ds9, but you can see a graph of it by using a region
*** HR cube
:PROPERTIES:
:TABLE_EXPORT_FILE: wavsec-startwavs.tab
:TABLE_EXPORT_FORMAT: orgtbl-to-tsv
:ID:       C2108CD1-EF28-4F63-9CA1-B7F9DA59C450
:END:
+ Exactly the same, except that NV = 5614
  + Wavelength scale: 0.85 angstroms
  + CRPIX3 = 1
  + CRVAL3 = 4595.
+ First try at dividing it up: do it by wavelength
  + Divide into 8 parts of length 702
    + Last one will be 700
  + Size will be 0.702 1.476 1.766 4 = 7.32 GB




#+name: wavsec-startwavs
| Section |  CRVAL3 |
|---------+---------|
|       0 | 4595.00 |
|       1 | 5191.70 |
|       2 | 5788.40 |
|       3 | 6385.10 |
|       4 | 6981.80 |
|       5 | 7578.50 |
|       6 | 8175.20 |
|       7 | 8771.90 |
#+TBLFM: $2=4595.0 + 0.85 702 $1 ;f2

#+BEGIN_SRC python :tangle muse_divide_cube_in_sections.py
  import sys
  from astropy.io import fits
  from astropy import wcs
  import numpy as np

  try:
      quantity = sys.argv[1]
      assert quantity in ['data', 'variance']
  except (IndexError, AssertionError) as e:
      sys.exit('Usage: {} (data|variance)'.format(sys.argv[0]))


  if quantity == 'variance':
      cubename = 'STAT'
  else:
      cubename = 'DATA'
    
  hdulist = fits.open('DATA/DATACUBEFINALuser_20140216T010259_78380e1d.fits')
  cube = hdulist[cubename]
  sections = np.arange(8, dtype=int)
  NV = 702
  k1_list = sections*NV
  k2_list = k1_list + NV
  wav0_list = cube.header['CRVAL3'] + cube.header['CD3_3']*NV*sections
  for section, k1, k2, wav0 in zip(sections, k1_list, k2_list, wav0_list):
      fn = 'muse-hr-{}-wavsec{}.fits'.format(quantity, section)
      hdr = cube.header.copy()
      hdr['CRVAL3'] = wav0
      hdr['NAXIS3'] = NV
      print('Writing', fn)
      fits.PrimaryHDU(header=hdr, data=cube.data[k1:k2]).writeto(fn, clobber=True)


#+END_SRC


+ That version is having problems with the later sections - memory usage is increasing, which is not good. 
+ So I will try a version that does only one section and then stops
+ Actually it looks like it is OK, so I won't need this version
  + Turns out that =watch ls -l PATTERN= only matches =PATTERN= once at the start, so any new files don't show up.  Better to use =watch -d ls -lth=
+ It takes 3 to 5 min per section to extract
+ File transfer to hypatia takes 8 min per section, so that is the limiting factor
#+BEGIN_SRC python :tangle muse_divide_and_conquer.py
  import sys
  from astropy.io import fits
  from astropy import wcs
  import numpy as np

  sections = np.arange(8, dtype=int)
  NV = 702
  k1_list = sections*NV
  k2_list = k1_list + NV

  try:
      quantity = sys.argv[1]
      section = int(sys.argv[2])
      assert quantity in ['data', 'variance']
      assert section in sections
  except (IndexError, AssertionError) as e:
      sys.exit('Usage: {} (data|variance) SECTION'.format(sys.argv[0]))


  if quantity == 'variance':
      cubename = 'STAT'
  else:
      cubename = 'DATA'
  
  hdulist = fits.open('DATA/DATACUBEFINALuser_20140216T010259_78380e1d.fits')
  cube = hdulist[cubename]

  wav0_list = cube.header['CRVAL3'] + cube.header['CD3_3']*NV*sections

  k1, k2, wav0 = k1_list[section], k2_list[section], wav0_list[section]
  fn = 'muse-hr-{}-wavsec{}.fits'.format(quantity, section)
  hdr = cube.header.copy()
  hdr['CRVAL3'] = wav0
  hdr['NAXIS3'] = NV
  print('Writing', fn)
  fits.PrimaryHDU(header=hdr, data=cube.data[k1:k2]).writeto(fn, clobber=True)


#+END_SRC
*** Ship all python files to server
#+BEGIN_SRC sh :results verbatim
rsync -avzP *.py nil:/fs/nil/other0/will/orion-muse
date
#+END_SRC

#+RESULTS:
: building file list ... 
:  0 files...26 files to consider
: muse_divide_cube_in_sections.py
:          922 100%    0.00kB/s    0:00:00         922 100%    0.00kB/s    0:00:00 (xfer#1, to-check=7/26)
: 
: sent 1202 bytes  received 54 bytes  2512.00 bytes/sec
: total size is 49553  speedup is 39.45
: Thu Oct 29 10:37:00 CST 2015

*** Heliocentric correction
Again, these snippets need to be run on the CRyA server where the big data cubes are
**** Looking for keywords in the top-level header
#+BEGIN_SRC python
hdr = hdulist[0].header
hdr.tofile('HRcube.hdr', sep='\n', padding=False)
#+END_SRC

#+RESULTS:

#+BEGIN_EXAMPLE
SIMPLE  =                    T / file does conform to FITS standard             
BITPIX  =                    8 / number of bits per data pixel                  
NAXIS   =                    0 / number of data axes                            
EXTEND  =                    T / FITS dataset may contain extensions            
COMMENT   FITS (Flexible Image Transport System) format is defined in 'Astronomy
COMMENT   and Astrophysics', volume 376, page 359; bibcode: 2001A&A...376..359H 
DATE    = '2014-11-13T08:54:24' / file creation date (YYYY-MM-DDThh:mm:ss UT)   
ORIGIN  = 'TEST    '           / European Southern Observatory                  
TELESCOP= 'ESO-VLT-U4'         / ESO <TEL>                                      
INSTRUME= 'MUSE    '           / Instrument used.                               
RA      =            83.780509 / [deg] 05:35:07.3 RA (J2000) pointing           
DEC     =             -5.39556 / [deg] -05:23:44.0 DEC (J2000) pointing         
EQUINOX =                2000. / Standard FK5                                   
RADECSYS= 'FK5     '           / Coordinate system                              
EXPTIME =                   5. / Integration time                               
MJD-OBS =       56704.04374097 / Obs start                                      
DATE-OBS= '2014-02-16T01:02:59.219' / Observing date                            
UTC     =                3770. / [s] 01:02:49.000 UTC                           
LST     =             21901.85 / [s] 06:05:01.850 LST                           
PI-COI  = 'UNKNOWN '           / PI-COI name.                                   
OBSERVER= 'UNKNOWN '           / Name of observer.                              
PIPEFILE= 'DATACUBE_FINAL.fits' / Filename of data product                      
BUNIT   = '10**(-20)*erg/s/cm**2/Angstrom'                                      
DATAMD5 = '69173383d3718d3ddb46e187f4cc2954' / MD5 checksum                     
OBJECT  = 'M42-lr  '           / Original target.                               
CHECKSUM= 'NcfSOcZPNcdPNcZP'   / HDU checksum updated 2014-11-12T22:17:16       
DATASUM = '0       '           / data unit checksum updated 2014-11-12T22:17:16 
HIERARCH ESO OBS AIRM =     5. / Req. max. airmass                              
HIERARCH ESO OBS AMBI FWHM = 2. / Req. max. seeing 
... ETC ...        
#+END_EXAMPLE

So, this does have the info that we need: RA, DEC, MJD-OBS in particula
